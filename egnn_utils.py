# -*- coding: utf-8 -*-
"""egnn_testing_emulate_run.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CR4v-CYB9Ej4IMsP2bQmtiRrd7XH5stx
"""

# !pip install mdtraj
# !pip install torch_geometric
# !pip install torch_cluster -f https://data.pyg.org/whl/torch-2.6.0+cu121.html
# !git clone https://github.com/bio-phys/aimmd.git

# base
import logging
import sys
import numpy as np
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import os.path as osp
import os
import random

# paths
import mdtraj as mdt

# torch
import torch
import torch.nn as nn
from torch.utils.data import Subset, random_split
from torch_geometric.data import Data, Dataset
from torch_geometric.loader import DataLoader
from torch_geometric.nn import radius_graph

SEED = 42

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed) # For multi-GPU setups

set_seed(SEED)

# Note: This can slightly slow down your training
# torch.backends.cudnn.deterministic = True
# torch.backends.cudnn.benchmark = False

os.cpu_count()

# print config
logging.basicConfig(
    force=True,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stdout
)

ATOMIC_NUMBER_TO_IDX = {3: 0, 17: 1, 8: 2, 1: 3}
IDX_TO_NAME = {0: 'Lithium (Li)', 1: 'Chlorine (Cl)', 2: 'Oxygen (O)', 3: 'Hydrogen (H)'}
NUM_ATOM_TYPES = 4

def mdtraj_to_graph_tensors(traj, cutoff_radius=0.5, atom_indices_to_keep=None):
    """
    Converts a single frame mdtraj.Trajectory object to graph tensors.
    Optionally, it can operate on a subset of atoms.
    """
    # If a subset of atoms is provided, slice the trajectory first
    traj = traj
    if atom_indices_to_keep is not None:
        traj = traj.atom_slice(atom_indices_to_keep)

    positions = torch.tensor(traj.xyz[0], dtype=torch.float)
    atomic_numbers = [atom.element.atomic_number for atom in traj.topology.atoms]

    node_features_one_hot = torch.zeros(len(atomic_numbers), NUM_ATOM_TYPES)
    for i, atomic_num in enumerate(atomic_numbers):
        if atomic_num in ATOMIC_NUMBER_TO_IDX:
            node_features_one_hot[i, ATOMIC_NUMBER_TO_IDX[atomic_num]] = 1.0

    edge_index = radius_graph(positions, r=cutoff_radius, loop=False)

    return {
        'x': node_features_one_hot,
        'pos': positions,
        'edge_index': edge_index
    }

# model from geom3d
def unsorted_segment_sum(data, segment_ids, num_segments):
    """Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`."""
    result_shape = (num_segments, data.size(1))
    result = data.new_full(result_shape, 0)  # Init empty result tensor.
    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))
    result.scatter_add_(0, segment_ids, data)
    return result


class E_GCL(nn.Module):
    def __init__(
        self,
        input_nf,
        output_nf,
        hidden_nf,
        edges_in_d=0,
        nodes_attr_dim=0,
        act_fn=nn.ReLU(),
        positions_weight=1.0,
        recurrent=True,
        attention=False,
        clamp=False,
        norm_diff=False,
        tanh=False,
    ):

        super(E_GCL, self).__init__()
        input_edge = input_nf * 2
        self.positions_weight = positions_weight
        self.recurrent = recurrent
        self.attention = attention
        self.norm_diff = norm_diff
        self.tanh = tanh
        edge_positions_nf = 1

        self.edge_mlp = nn.Sequential(
            nn.Linear(input_edge + edge_positions_nf + edges_in_d, hidden_nf),
            act_fn,
            nn.Linear(hidden_nf, hidden_nf),
            act_fn,
        )

        self.node_mlp = nn.Sequential(
            nn.Linear(hidden_nf + input_nf + nodes_attr_dim, hidden_nf),
            act_fn,
            nn.Linear(hidden_nf, output_nf),
        )

        layer = nn.Linear(hidden_nf, 1, bias=False)
        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)

        self.clamp = clamp
        positions_mlp = []
        positions_mlp.append(nn.Linear(hidden_nf, hidden_nf))
        positions_mlp.append(act_fn)
        positions_mlp.append(layer)
        if self.tanh:
            positions_mlp.append(nn.Tanh())
            self.positions_range = nn.Parameter(torch.ones(1)) * 3
        self.positions_mlp = nn.Sequential(*positions_mlp)

        if self.attention:
            self.att_mlp = nn.Sequential(nn.Linear(hidden_nf, 1), nn.Sigmoid())
        return

    def edge_model(self, source, target, radial, edge_attr):
        if edge_attr is None:  # Unused.
            out = torch.cat([source, target, radial], dim=1)
        else:
            out = torch.cat([source, target, radial, edge_attr], dim=1)
        out = self.edge_mlp(out)
        if self.attention:
            att_val = self.att_mlp(out)
            out = out * att_val
        return out

    def node_model(self, x, edge_index, edge_attr, node_attr):
        row, col = edge_index
        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0))
        if node_attr is not None:
            agg = torch.cat([x, agg, node_attr], dim=1)
        else:
            agg = torch.cat([x, agg], dim=1)
        out = self.node_mlp(agg)
        if self.recurrent:
            out = x + out
        return out, agg

    def positions_model(self, positions, edge_index, positions_diff, edge_feat):
        row, col = edge_index
        trans = positions_diff * self.positions_mlp(edge_feat)
        trans = torch.clamp(
            trans, min=-100, max=100
        )  # This is never activated but just in case it case it explosed it may save the train
        agg = unsorted_segment_sum(trans, row, num_segments=positions.size(0))
        positions += agg * self.positions_weight
        return positions

    def positions2radial(self, edge_index, positions):
        row, col = edge_index
        positions_diff = positions[row] - positions[col]
        radial = torch.sum((positions_diff) ** 2, 1).unsqueeze(1)

        if self.norm_diff:
            norm = torch.sqrt(radial) + 1
            positions_diff = positions_diff / (norm)

        return radial, positions_diff

    def forward(self, h, positions, edge_index, node_attr=None, edge_attr=None):
        """
        h: (N, emb)
        positions: (N, 3)
        edge_index: (2, M)
        node_attr: None or (N, node_input_dim), where node_input_dim=1
        edge_attr: None or (M, edge_input_dim)
        """
        row, col = edge_index
        radial, positions_diff = self.positions2radial(
            edge_index, positions
        )  # (2N, 1), (N, 3)
        edge_feat = self.edge_model(h[row], h[col], radial, edge_attr)  # (M, n_emb)

        # positions = self.positions_model(positions, edge_index, positions_diff, edge_feat)  # (M, 3)
        h, agg = self.node_model(
            h, edge_index, edge_feat, node_attr
        )  # (N, emb_dim), (N, emb_dim*2 + input_node_dim)
        return h, positions, edge_attr


    def forward_with_gathered_index(self, h, positions, edge_index, node_attr, periodic_index_mapping):
        row, col = edge_index
        radial, positions_diff = self.positions2radial(
            edge_index, positions
        )  # (2N, 1), (N, 3)

        gathered_row = periodic_index_mapping[row]
        gathered_col = periodic_index_mapping[col]
        edge_feat = self.edge_model(h[gathered_row], h[gathered_col], radial, edge_attr)  # (M, n_emb)

        h, agg = self.node_model(
            h, edge_index, edge_feat, node_attr
        )  # (N, emb_dim), (N, emb_dim*2 + input_node_dim)
        return h, positions, edge_attr



class EGNN(nn.Module):
    def __init__(
        self,
        in_node_nf,
        in_edge_nf,
        hidden_nf,
        act_fn=nn.SiLU(),
        n_layers=4,
        positions_weight=1.0,
        attention=True,
        node_attr=True,
    ):
        super(EGNN, self).__init__()
        self.hidden_nf = hidden_nf
        self.n_layers = n_layers

        self.embedding = nn.Linear(in_node_nf, hidden_nf)
        self.node_attr = node_attr

        if node_attr:
            n_node_attr = in_node_nf
        else:
            n_node_attr = 0

        for i in range(0, n_layers):
            layer_ = E_GCL(
                self.hidden_nf,
                self.hidden_nf,
                self.hidden_nf,
                edges_in_d=in_edge_nf,
                nodes_attr_dim=n_node_attr,
                positions_weight=positions_weight,
                act_fn=act_fn,
                recurrent=True,
                attention=attention,
            )
            self.add_module("gcl_%d" % i, layer_)

        self.node_dec = nn.Sequential(
            nn.Linear(self.hidden_nf, self.hidden_nf),
            act_fn,
            nn.Linear(self.hidden_nf, self.hidden_nf),
        )

                # Store all arguments needed to recreate this module.
        # We use locals() to capture them all automatically.
        self.call_kwargs = locals()
        del self.call_kwargs['self']
        del self.call_kwargs['__class__']
        # The act_fn is an object, not easily serializable, so we remove it.
        # The default nn.SiLU() will be used on recreation, which is what we want.
        del self.call_kwargs['act_fn'] 
        
        return


    def forward(self, x, positions, edge_index, edge_attr=None):
        h = self.embedding(x)

        for i in range(self.n_layers):
            if self.node_attr:
                h, _, _ = self._modules["gcl_%d" % i](
                    h, positions, edge_index, node_attr=x, edge_attr=edge_attr
                )
            else:
                h, _, _ = self._modules["gcl_%d" % i](
                    h, positions, edge_index, node_attr=None, edge_attr=edge_attr
                )

        h = self.node_dec(h)
        return h

    def forward_with_gathered_index(self, gathered_x, positions, edge_index, periodic_index_mapping):
        h = self.embedding(gathered_x)

        for i in range(self.n_layers):
            if self.node_attr:
                h, _, _ = self._modules["gcl_%d" % i].forward_with_gathered_index(
                    h, positions, edge_index, node_attr=gathered_x, periodic_index_mapping=periodic_index_mapping
                )
            # else:
            #     h, _, _ = self._modules["gcl_%d" % i](
            #         h, positions, edge_index, node_attr=None, edge_attr=edge_attr
            #     )

        h = self.node_dec(h)
        return h

# modified, for the commitor prediction
class PooledEGNN(nn.Module):
    def __init__(self, hidden_nf, n_out=1, **egnn_kwargs):
        super().__init__()
        egnn_kwargs['hidden_nf'] = hidden_nf
        # Create the inner EGNN model inside this class
        self.egnn = EGNN(**egnn_kwargs)
        
        self.pooler = nn.Sequential(
            nn.Linear(hidden_nf, hidden_nf // 2), nn.SiLU(),
            nn.Linear(hidden_nf // 2, n_out)
        )
        
        # Store all kwargs needed for recreation
        self.call_kwargs = {
            'hidden_nf': hidden_nf,
            'n_out': n_out,
            'egnn_kwargs': egnn_kwargs
        }
    def forward(self, data):
        node_features = data.x
        positions = data.pos
        edge_index = data.edge_index

        batch_vector = data.batch

        node_embeddings = self.egnn(node_features, positions, edge_index, edge_attr=None)

        summed_embeddings = unsorted_segment_sum(node_embeddings, batch_vector, num_segments=data.num_graphs)

        num_nodes_per_graph = torch.bincount(batch_vector, minlength=data.num_graphs).unsqueeze(1)
        mean_embeddings = summed_embeddings / num_nodes_per_graph.clamp(min=1) # avoid division by zero

        return self.pooler(mean_embeddings)

def find_proximal_atom_indices(traj, proximity_cutoff_nm, ion_selection_strings):
    """
    Finds atoms that are part of residues that are ever within a certain distance of specified ions.

    Args:
        traj (mdt.Trajectory): The full trajectory to analyze.
        ion_selection_strings (list of str): A list of mdtraj selection strings for the central ions (e.g., ["resname Li", "resname Cl"]).
        proximity_cutoff_nm (float): The distance in nanometers to define 'proximity'.

    Returns:
        np.ndarray: An array of atom indices to keep (ions + all atoms of proximal water molecules).
    """
    traj = traj
    logging.info(f"Finding atoms within {proximity_cutoff_nm} nm of ions...")

    ion_indices = traj.topology.select(' or '.join(ion_selection_strings))
    water_oxygen_indices = traj.topology.select("water and name O")
    atom_pairs = np.array([(i, j) for i in ion_indices for j in water_oxygen_indices])
    distances = mdt.compute_distances(traj, atom_pairs)
    min_distances = np.min(distances, axis=0)
    min_distances_per_water = np.min(min_distances.reshape(len(ion_indices), len(water_oxygen_indices)), axis=0)
    proximal_water_oxygen_indices = water_oxygen_indices[min_distances_per_water <= proximity_cutoff_nm]
    proximal_residue_indices = set(traj.topology.atom(idx).residue.index for idx in proximal_water_oxygen_indices)
    logging.info(f"Found {len(proximal_residue_indices)} water molecules that come close to the ions.")
    proximal_water_atom_indices = [atom.index for atom in traj.topology.atoms if atom.residue.index in proximal_residue_indices]
    final_atom_indices_to_keep = np.union1d(ion_indices, proximal_water_atom_indices).astype(int)

    return final_atom_indices_to_keep

def find_proximal_indices_for_snapshot(traj_snapshot, radius_nm, ion_selection_strings):
    """
    Finds atoms that are part of residues within a certain distance of specified ions in a single frame.

    Args:
        traj_snapshot (mdt.Trajectory): A single-frame trajectory to analyze.
        radius_nm (float): The distance in nanometers to define 'proximity'.
        ion_selection_strings (list of str): A list of mdtraj selection strings for the central ions.

    Returns:
        np.ndarray: An array of atom indices to keep (ions + all atoms of proximal water molecules).
    """
    traj_snapshot = traj_snapshot # amen
    ion_indices = traj_snapshot.topology.select(' or '.join(ion_selection_strings))
    nearby_waters = mdt.compute_neighbors(traj_snapshot, radius_nm, ion_indices,
                                          haystack_indices=traj_snapshot.topology.select("water and name O"))
    if not nearby_waters or len(nearby_waters[0]) == 0:
        return ion_indices
    proximal_residue_indices = set(traj_snapshot.topology.atom(idx).residue.index for idx in nearby_waters[0])
    proximal_water_atom_indices = [atom.index for atom in traj_snapshot.topology.atoms if atom.residue.index in proximal_residue_indices]
    return np.union1d(ion_indices, proximal_water_atom_indices).astype(int)

# class TrajectoryGNNData(Dataset):
#     def __init__(self, root, train_configs, shot_results_array, cutoff_radius=0.5,
#                  transform=None, pre_transform=None,
#                  global_atom_indices=None, per_snapshot_selection_radius=None):
#         self.train_configs = train_configs
#         self.shot_results_array = shot_results_array
#         self.cutoff_radius = cutoff_radius
#         self.global_atom_indices = global_atom_indices
#         self.per_snapshot_selection_radius = per_snapshot_selection_radius

#         # Validate that only one selection method is chosen
#         if global_atom_indices is not None and per_snapshot_selection_radius is not None:
#             raise ValueError("Please provide either 'global_atom_indices' or 'per_snapshot_selection_radius', not both.")

#         super().__init__(root, transform, pre_transform)

#     property
#     def raw_file_names(self):
#         return []

#     property
#     def processed_file_names(self):
#         return [f'data_{i}.pt' for i in range(len(self.train_configs))]

#     def process(self):
#         for i, traj_config in enumerate(tqdm(self.train_configs, desc="Processing data for saving")):
#             atom_indices_for_this_graph = self.global_atom_indices

#             if self.per_snapshot_selection_radius is not None:
#                 # Calculate indices for this specific snapshot
#                 atom_indices_for_this_graph = find_proximal_indices_for_snapshot(traj_config, self.per_snapshot_selection_radius, ion_selection_strings=["resname Li", "resname Cl"])

#             graph_tensors = mdtraj_to_graph_tensors(
#                 traj_config,
#                 cutoff_radius=self.cutoff_radius,
#                 atom_indices_to_keep=atom_indices_for_this_graph
#             )
#             shot_result = self.shot_results_array[i]
#             data = Data(
#                 x=graph_tensors['x'],
#                 edge_index=graph_tensors['edge_index'],
#                 pos=graph_tensors['pos'],
#                 y=torch.tensor(shot_result, dtype=torch.float).unsqueeze(0)
#             )
#             torch.save(data, osp.join(self.processed_dir, f'data_{i}.pt'))

#     def len(self):
#         return len(self.train_configs)

#     def get(self, idx):
#         data = torch.load(osp.join(self.processed_dir, self.processed_file_names[idx]), weights_only=False)
#         return data

class TrajectoryGNNData(Dataset):
    def __init__(self, root, train_configs, shot_results_array, cutoff_radius=0.5,
                 transform=None, pre_transform=None,
                 global_atom_indices=None, per_snapshot_selection_radius=None):
        self.train_configs = train_configs
        self.shot_results_array = shot_results_array
        self.cutoff_radius = cutoff_radius
        self.global_atom_indices = global_atom_indices
        self.per_snapshot_selection_radius = per_snapshot_selection_radius

        if global_atom_indices is not None and per_snapshot_selection_radius is not None:
            raise ValueError("Please provide either 'global_atom_indices' or 'per_snapshot_selection_radius', not both.")

        super().__init__(root, transform, pre_transform)
        # Load the processed data into memory once
        self.data_list = torch.load(self.processed_paths[0],weights_only=False)

    @property
    def raw_file_names(self):
        return []

    @property
    def processed_file_names(self):
        # We will now save to a single file
        return ['data.pt']

    def process(self):
        data_list = [] # Create a list to hold all graph objects

        for i, traj_config in enumerate(tqdm(self.train_configs, desc="Processing data for saving")):
            atom_indices_for_this_graph = self.global_atom_indices

            if self.per_snapshot_selection_radius is not None:
                atom_indices_for_this_graph = find_proximal_indices_for_snapshot(
                    traj_config, self.per_snapshot_selection_radius, ion_selection_strings=["resname Li", "resname Cl"]
                )

            graph_tensors = mdtraj_to_graph_tensors(
                traj_config,
                cutoff_radius=self.cutoff_radius,
                atom_indices_to_keep=atom_indices_for_this_graph
            )
            shot_result = self.shot_results_array[i]
            data = Data(
                x=graph_tensors['x'],
                edge_index=graph_tensors['edge_index'],
                pos=graph_tensors['pos'],
                y=torch.tensor(shot_result, dtype=torch.float).unsqueeze(0)
            )
            data_list.append(data) # Append the graph object to the list

        # Save the entire list of graphs to a single file
        torch.save(data_list, self.processed_paths[0])

    def len(self):
        # The length is the number of items in our loaded list
        return len(self.data_list)

    def get(self, idx):
        # Retrieve the graph directly from the in-memory list
        return self.data_list[idx]

# loss for batch
def binomial_loss_batch_fn(q_pred_batch, shots_tensor_batch):

    q_pred_batch = q_pred_batch.squeeze(-1)

    loss_per_item = (
        shots_tensor_batch[:, 0] * torch.nn.functional.softplus(q_pred_batch) +
        shots_tensor_batch[:, 1] * torch.nn.functional.softplus(-q_pred_batch)
    )

    return loss_per_item.mean()


