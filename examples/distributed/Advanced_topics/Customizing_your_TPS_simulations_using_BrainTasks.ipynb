{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `BrainTask`s or how to customize your TPS simulation\n",
    "\n",
    "As already mentioned in the example notebooks that show how to run a TPS simulation with `aimmd.distributed`, the central object of the TPS simulation (the `Brain`) runs all its `BrainTask`s after every Monte Carlo step. This is very similar to the concept of a `hook` in `openpathsampling` with the difference that `openpathsampling` defines pre- and post-step hooks, while in `aimmd.distributed` the `BrainTask`s are only called after the Monte Carlo step, i.e. only post-step hooks are currently implemented. Importantly, in `aimmd.distributed` the `BrainTasks`s are run after completing but before saving the Monte Carlo step, which enables the tasks to add additional information to the Monte Carlo steps.\n",
    "\n",
    "In addition the the predefined `BrainTask`s to e.g. train the model, save the trainset, and perform the density collection (for the density correction in $\\phi_B$-space), users can easily define their own `BrainTask`s to modify the behavior of their TPS simulation. To this end one just needs to subclass the `BrainTask` abstract base class and attach the resulting user-defined `BrainTask` to the `Brain` as usual.\n",
    "\n",
    "**Required knowledge/recommended reading**: This notebook assumes that you are familiar with setting up and running a TPS simulation using `aimmd.distributed`. If you are not familliar with running an `aimmd.distributed` TPS simulation, please have a look at the notebooks `TPS_1_setup_and_run_simulation.ipynb` to `TPS_4_rerun_with_changed_parameters_or_recover_crashed_simulations.ipynb` or `TPS_with_EQ_SPs_1_generate_SPs_from_UmbrellaSampling.ipynb` to `TPS_with_EQ_SPs_4_rerun_with_changed_parameters_or_recover_crashed_simulations.ipynb` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/think/.conda/envs/aimmd_dev/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n",
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx\n",
    "from asyncmd import Trajectory\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "#scratch_dir = \"/homeloc/scratch/aimmd_distributed/\"\n",
    "scratch_dir = \".\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"TransitionPathSampling_ala_customizing_TPS_with_BrainTasks\")\n",
    "if not os.path.isdir(workdir):\n",
    "    os.mkdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined `BrainTask`s\n",
    "\n",
    "As mentioned above, we will subclass the `aimmd.distributed.pathsampling.BrainTask` abstract base class to define our own `BrainTask`.\n",
    "\n",
    "The only two methods we need to define are `__init__` (to initialize our class) and `run` (which will be called after every Monte Carlo step by the `Brain`). The `run` method will be called with three arguments: the `Brain` which performs the simulation, the Monte Carlo step that just finished and the index of the sampler that produced the Monte Carlo step. It will be called after the Monte Carlo step finished but before it is saved, i.e. the `BrainTask`s can add or modify attributes of the Monte Carlo step and these changes will be permanent.\n",
    "\n",
    "Below are two (somewhat useless to dangerous) examples for user-defined `BrainTask`s:\n",
    "\n",
    "- The `VerbosePrintTask` just prints some info every time it gets called with a Monte Carlo step. Note that its job can be done by the `Brain` itself if you call the `Brain`s `run_for_n_steps` or `run_for_n_accepts` methods with `print_progress=1` when running the simulation. I.e. this `BrainTask` is just somewhat useless.\n",
    "\n",
    "- The `StupidTask` does something arguably very stupid, namely that it breaks the Markov Chain Monte Carlo by modifying the Monte Carlo step to a non-accepted step if its acceptance probability is smaller than `p_cut`. This is done here mostly to showcase that `BrainTask`s are a powerfull tool which enables you to do (almost) arbitrary things to modify the behavior of your TPS simulation, if they make sense is another story. As always: With great power comes great responsibility and great potential for mistakes ;) You could however use the capability to modify Monte Carlo steps in a useful way to e.g. perform swap moves between two different samplers using a `BrainTask` that waits for both of them to finish and then attempts a swap.\n",
    "\n",
    "Note that each `BrainTask` will be run if the stepnumber is divisible by `interval`, e.g. a `BrainTask` with `interval=3` will only be run after the 3rd, 6th, 9th, etc. Monte Carlo step. Furthermore, `BrainTasks` are called in the order in which they are passed to the `Brain`, e.g. if you pass `tasks= [VerbosePrintTask(), StupidTask()]` then the `VerbosePrintTask` will always run before the `StupidTask` (at least if they both are supposed to run at a given stepnumber)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aimmd.distributed\n",
    "from aimmd.distributed.pathmovers import MCstep  # only needed for the type hints\n",
    "\n",
    "\n",
    "class VerbosePrintTask(aimmd.distributed.pathsampling.BrainTask):\n",
    "    def __init__(self, interval: int = 1, name: str = \"VerbosePrintTask\"):\n",
    "        super().__init__(interval)\n",
    "        self._call_count = 0\n",
    "        self.name = name\n",
    "\n",
    "    async def run(self, brain, mcstep: MCstep, sampler_idx: int):\n",
    "        # This will be called every `interval` finished Monte Carlo steps\n",
    "        self._call_count += 1  # increment call count to see how many times we call run\n",
    "        # We just print some basic info\n",
    "        print(f\"A sampler ({brain.samplers[sampler_idx]}) (index={sampler_idx}) \"\n",
    "              f\"produced a Monte Carlo step ({mcstep}).\\n\"\n",
    "              f\"This BrainTask with name {self.name} ({self}) got called for the {self._call_count}th time.\"\n",
    "              )\n",
    "\n",
    "\n",
    "class StupidTask(aimmd.distributed.pathsampling.BrainTask):\n",
    "    def __init__(self, interval: int = 1, p_cut: float = 0.5):\n",
    "        super().__init__(interval)\n",
    "        self.p_cut = p_cut\n",
    "\n",
    "    async def run(self, brain, mcstep: MCstep, sampler_idx: int):\n",
    "        if mcstep.p_acc <= self.p_cut:\n",
    "            mcstep.accepted = False\n",
    "\n",
    "\n",
    "class MakeEveryStepAcceptedTask(aimmd.distributed.pathsampling.BrainTask):\n",
    "    def __init__(self, interval: int = 1):\n",
    "        super().__init__(interval)\n",
    "\n",
    "    async def run(self, brain, mcstep: MCstep, sampler_idx: int):\n",
    "        if not mcstep.accepted:\n",
    "            # modify non-accepted steps to be accepted\n",
    "            # NOTE: this will (most likely) crash a sequential TPS simulation\n",
    "            #       because steps that are not accepted do not need to contain\n",
    "            #       a valid transition (i.e. their `path` attribute is not set)\n",
    "            #       so we can not start a new Monte Carlo step by shooting from\n",
    "            #       the last transition path\n",
    "            #       In a TPS simulation with equilibrium shooting points this\n",
    "            #       BrainTask will not have any effect because there every step\n",
    "            #       is formally accepted (and has an associated weight which\n",
    "            #       can be zero)\n",
    "            mcstep.accepted = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the TPS simulation\n",
    "\n",
    "This is the same setup as used in `TPS_1_setup_and_run_simulation.ipynb`, just with less comments and explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit 1 is 66 units wide.\n",
      "Dropout before it is 0.18674307214231128.\n",
      "ResUnit 2 is 41 units wide.\n",
      "Dropout before it is 0.1162432499771616.\n",
      "ResUnit 3 is 25 units wide.\n",
      "Dropout before it is 0.07235873872180604.\n",
      "ResUnit 4 is 16 units wide.\n",
      "Dropout before it is 0.045041643884176266.\n",
      "ResUnit 5 is 10 units wide.\n",
      "Dropout before it is 0.02803738317757008.\n"
     ]
    }
   ],
   "source": [
    "# number of samplers\n",
    "n_samplers = 2  # results in 2*n_samplers gmx engines\n",
    "\n",
    "# storage file\n",
    "storage = aimmd.Storage(os.path.join(workdir, \"storage.h5\"))\n",
    "\n",
    "# state functions and descriptor transform function\n",
    "os.chdir(\"..\")  # chdir to one level above to import state_funcs_mda.py\n",
    "from state_funcs_mda import alpha_R, C7_eq, descriptor_func_ic\n",
    "os.chdir(\"Advanced_topics\")  # and back to the folder in which we run the notebook\n",
    "# state functions\n",
    "wrapped_alphaR = asyncmd.trajectory.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "wrapped_C7_eq = asyncmd.trajectory.PyTrajectoryFunctionWrapper(C7_eq)\n",
    "# descriptor transform\n",
    "# descriptor_func_ic gives us an internal coordinate representation (i.e. bond lengths, angles and dihedrals)\n",
    "wrapped_transform = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_ic,\n",
    "                                                                   call_kwargs={\"molecule_selection\": \"protein\"},\n",
    "                                                                   )\n",
    "\n",
    "# Underlying dynamics/ Define the engine(s) for the PathMovers (they will all be the same)\n",
    "gro = \"../gmx_infiles/conf.gro\"\n",
    "top = \"../gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"../gmx_infiles/index.ndx\"\n",
    "mdp = asyncgmx.MDP(\"../gmx_infiles/md.mdp\")\n",
    "gmx_engine_kwargs = {\"mdconfig\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"output_traj_type\": \"XTC\",\n",
    "                     #\"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     \"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = asyncgmx.GmxEngine\n",
    "\n",
    "# initial transition\n",
    "tp_initial = Trajectory(structure_file=\"../gmx_infiles/ala_300K_amber99sb-ildn.tpr\",\n",
    "                        trajectory_files=\"../gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr\",\n",
    "                        )\n",
    "\n",
    "# Model definition\n",
    "# first get the descriptors for them to infer the number of inputs for our model\n",
    "descriptors_for_initial_tp = await wrapped_transform(tp_initial)\n",
    "# architecture specification\n",
    "n_lay_pyramid = 5  # number of resunits\n",
    "n_unit_top = 10  # number of units in the last layer before the log_predictor\n",
    "dropout_base = 0.3  # dropot fraction in the first layer (will be reduced going to the top)\n",
    "n_unit_base = cv_ndim = descriptors_for_initial_tp.shape[1]  # input dimension\n",
    "# the factor by which we reduce the number of units per layer (the width) and the dropout fraction\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "modules = []\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    modules += [aimmd.pytorch.networks.FFNet(n_in=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                             n_hidden=[max(n_unit_top, int(n_unit_base * fact**i))],  # 1 hidden layer network\n",
    "                                             activation=torch.nn.Identity(),\n",
    "                                             dropout={\"0\": dropout_base * fact**i}\n",
    "                                             )\n",
    "                ]\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i)))} units wide.\")\n",
    "    print(f\"Dropout before it is {dropout_base * fact**i}.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1, modules=modules)\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "# optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)\n",
    "# wrapp the pytorch neural network model in a RCModel class,\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,\n",
    "                                                            'lr_min': 5e-5,\n",
    "                                                            'epochs_per_train': 3,\n",
    "                                                            'window': 100,\n",
    "                                                            'batch_size': 8192,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_transform,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )\n",
    "\n",
    "# Define the TPS sampling scheme\n",
    "# shooting point selection\n",
    "spselector = aimmdd.spselectors.RCModelSPSelectorFromTraj()\n",
    "# and setup the movers lists (i.e. mover_cls and mover_kwargs for each sampler)\n",
    "# here we just use one move-type per sampler and therefore only have one entry\n",
    "# in each list\n",
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  #'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": spselector,\n",
    "                  \"max_steps\": 500 * 10**5,  # 500 steps * dt (2 fs) = 1 ps\n",
    "                  }\n",
    "                 ]\n",
    "\n",
    "# Trainset\n",
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `BrainTask`s\n",
    "\n",
    "Here we will initialize our user-defined `BrainTask`s and also the basic `BrainTask`s needed for a TPS simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    # TrainingTask\n",
    "    aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "    # SaveTask\n",
    "    aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset),\n",
    "    # DensityCollectionTask\n",
    "    aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                              first_collection=100,\n",
    "                                              recreate_interval=250,\n",
    "                                              ),\n",
    "    # this task will print after every finished Monte Carlo step\n",
    "    VerbosePrintTask(interval=1, name=\"VerbosePrintTask_interval=1\"),\n",
    "    # this task will print only every 3rd finished Monte Carlo step\n",
    "    VerbosePrintTask(interval=3, name=\"VerbosePrintTask_interval=3\"),\n",
    "    # p_cut=100 should result in no accepted Monte Carlo steps as we will only\n",
    "    # accept steps that have p_acc >= 100\n",
    "    # (p_cut=0. would result in no modified Monte Carlo steps at all)\n",
    "    StupidTask(interval=1, p_cut=100.),\n",
    "    # uncomment the next line if you want to crash your TPS simulation :)\n",
    "    #MakeEveryStepAcceptedTask(interval=1),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the `Brain` (and attach the `BrainTask`s)\n",
    "\n",
    "Also seed the initial transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = aimmdd.Brain.samplers_from_moverlist(model=model, workdir=workdir, storage=storage,\n",
    "                                             n_sampler=n_samplers,\n",
    "                                             movers_cls=movers_cls, movers_kwargs=movers_kwargs,\n",
    "                                             samplers_use_same_stepcollection=False,\n",
    "                                             tasks=tasks)\n",
    "# seed initial transition for each Markov chain sampler\n",
    "brain.seed_initial_paths(trajectories=[tp_initial])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3c4f0b0640>) (index=0) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=1, states_reached=[1. 1.], accepted=True, p_acc=8.33322158584474,\n",
      "       predicted_committors_sp=[0.536691], weight=1.0,\n",
      "       directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_1)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 1th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3c4f0b0640>) (index=0) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=1, states_reached=[1. 1.], accepted=True, p_acc=8.33322158584474,\n",
      "       predicted_committors_sp=[0.536691], weight=1.0,\n",
      "       directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_1)).\n",
      "This BrainTask with name VerbosePrintTask_interval=3 (<__main__.VerbosePrintTask object at 0x7f3c4f0b1ed0>) got called for the 1th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3d357b7790>) (index=1) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=1, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.53626174],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_1)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 2th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3c4f0b0640>) (index=0) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=2, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.53909445],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_2)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 3th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3d357b7790>) (index=1) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=2, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.5362103],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_2)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 4th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3d357b7790>) (index=1) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=2, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.5362103],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_2)).\n",
      "This BrainTask with name VerbosePrintTask_interval=3 (<__main__.VerbosePrintTask object at 0x7f3c4f0b1ed0>) got called for the 2th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3c4f0b0640>) (index=0) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=3, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.50561476],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_3)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 5th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3d357b7790>) (index=1) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=3, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.5066172],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_3)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 6th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3c4f0b0640>) (index=0) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=4, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.50562847],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_4)).\n",
      "This BrainTask with name VerbosePrintTask_interval=1 (<__main__.VerbosePrintTask object at 0x7f3c4f0b0f10>) got called for the 7th time.\n",
      "A sampler (<aimmd.distributed.pathsampling.PathChainSampler object at 0x7f3c4f0b0640>) (index=0) produced a Monte Carlo step (MCStep(mover=TwoWayShootingPathMover, stepnum=4, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.50562847],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_4)).\n",
      "This BrainTask with name VerbosePrintTask_interval=3 (<__main__.VerbosePrintTask object at 0x7f3c4f0b1ed0>) got called for the 3th time.\n"
     ]
    }
   ],
   "source": [
    "# we should call the second VerbosePrintTask 3 times and the first one 7 times\n",
    "await brain.run_for_n_steps(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on mcstepcollection with index 0.\n",
      "    Step with index 0: MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_0)\n",
      "    Step with index 1: MCStep(mover=TwoWayShootingPathMover, stepnum=1, states_reached=[1. 1.], accepted=False, p_acc=8.33322158584474,\n",
      "       predicted_committors_sp=[0.536691], weight=1.0,\n",
      "       directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_1)\n",
      "    Step with index 2: MCStep(mover=TwoWayShootingPathMover, stepnum=2, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.53909445],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_2)\n",
      "    Step with index 3: MCStep(mover=TwoWayShootingPathMover, stepnum=3, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.50561476],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_3)\n",
      "    Step with index 4: MCStep(mover=TwoWayShootingPathMover, stepnum=4, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.50562847],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_0/mcstep_4)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Working on mcstepcollection with index 1.\n",
      "    Step with index 0: MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_0)\n",
      "    Step with index 1: MCStep(mover=TwoWayShootingPathMover, stepnum=1, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.53626174],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_1)\n",
      "    Step with index 2: MCStep(mover=TwoWayShootingPathMover, stepnum=2, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.5362103],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_2)\n",
      "    Step with index 3: MCStep(mover=TwoWayShootingPathMover, stepnum=3, states_reached=[2. 0.], accepted=False, p_acc=0, predicted_committors_sp=[0.5066172],\n",
      "       weight=1, directory=TransitionPathSampling_ala_customizing_TPS_with_BrainTasks/sampler_1/mcstep_3)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "All steps (except for the initial seed steps) have been rejected: True\n"
     ]
    }
   ],
   "source": [
    "# check that no MCStep is accepted (if its acceptance probability is smaller than 100)\n",
    "all_steps = []\n",
    "for c_idx, collection in enumerate(storage.mcstep_collections):\n",
    "    print(f\"Working on mcstepcollection with index {c_idx}.\")\n",
    "    for s_idx, step in enumerate(collection):\n",
    "        print(f\"    Step with index {s_idx}: {step}\")\n",
    "        if s_idx != 0:\n",
    "            all_steps += [step]\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "print(f\"All steps (except for the initial seed steps) have been rejected: {not any(s.accepted for s in all_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the storage\n",
    "storage.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimmd dev (py3 Nov 2022)",
   "language": "python",
   "name": "aimmd_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
