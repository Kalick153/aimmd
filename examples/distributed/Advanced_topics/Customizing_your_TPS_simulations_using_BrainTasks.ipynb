{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `BrainTask`s or how to customize your TPS simulation\n",
    "\n",
    "As already mentioned in the example notebooks that show how to run a TPS simulation with `aimmd.distributed`, the central object of the TPS simulation (the `Brain`) runs all its `BrainTask`s after every Monte Carlo step. This is very similar to the concept of a `hook` in `openpathsampling` with the difference that `openpathsampling` defines pre- and post-step hooks, while in `aimmd.distributed` the `BrainTask`s are only called after the Monte Carlo step, i.e. only post-step hooks are currently implemented.\n",
    "\n",
    "In addition the the predefined `BrainTask`s to e.g. train the model, save the trainset, and perform the density collection (for the density correction in $\\phi_B$-space), users can easily define their own `BrainTask`s to modify the behavior of their TPS simulation. To this end one just needs to subclass the `BrainTask` abstract base class and attach the resulting user-defined `BrainTask` to the `Brain` as usual.\n",
    "\n",
    "**Required knowledge/recommended reading**: This notebook assumes that you are familiar with setting up and running a TPS simulation using `aimmd.distributed`. If you are not familliar with running an `aimmd.distributed` TPS simulation, please have a look at the notebooks `TPS_1_setup_and_run_simulation.ipynb` to `TPS_4_rerun_with_changed_parameters_or_recover_crashed_simulations.ipynb` or `TPS_with_EQ_SPs_1_generate_SPs_from_UmbrellaSampling.ipynb` to `TPS_with_EQ_SPs_4_rerun_with_changed_parameters_or_recover_crashed_simulations.ipynb` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hejung/miniconda3/envs/aimmd_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:asyncmd.slurm:Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n",
      "WARNING:aimmd:dCGPy not found. SymReg will not be available.\n",
      "WARNING:aimmd:Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx\n",
    "from asyncmd import Trajectory\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "scratch_dir = \"/homeloc/scratch/aimmd_distributed/\"\n",
    "#scratch_dir = \".\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"TransitionPathSampling_ala_customizing_TPS_with_BrainTasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined `BrainTask`s\n",
    "\n",
    "As mentioned above, we will subclass the `aimmd.distributed.pathsampling.BrainTask` abstract base class to define our own `BrainTask`.\n",
    "\n",
    "The only two methods we need to define are `__init__` (to initialize our class) and `run` (which will be called after every Monte Carlo step by the `Brain`). The `run` method will be called with three arguments: the `Brain` which performs the simulation, the Monte Carlo step that just finished and the index of the sampler that produced the Monte carlo step.\n",
    "\n",
    "Below are two (somewhat useless) examples for user-defined `BrainTask`s:\n",
    "\n",
    "- The `VerbosePrintTask` just prints some info every time it gets called with a Monte Carlo step. Note that its job can be done by the `Brain` itself if you call the `Brain`s `run_for_n_steps` or `run_for_n_accepts` methods with `print_progress=1` when running the simulation.\n",
    "\n",
    "- The `StupidTask` does something arguably stupid, namely that it breaks the Markov Chain Monte Carlo by modifying the Monte Carlo step to a non-accepted step if its acceptance probability is smaller than `p_cut`. This is done here mostly to showcase that `BrainTask`s are a powerfull tool which enables you to do (almost) arbitrary things to modify the behavior of your TPS simulation, if they make sense is another story. As always: With great power comes great responsibility and great potential for mistakes ;)\n",
    "\n",
    "Note that each `BrainTask` will be run if the stepnumber is divisible by `interval`, e.g. a `BrainTask` with `interval=3` will only be run after the 3rd, 6th, 9th, etc. Monte Carlo step. Furthermore, `BrainTasks` are called in the order in which they are passed to the `Brain`, e.g. if you pass `tasks= [VerbosePrintTask(), StupidTask()]` then the `VerbosePrintTask` will always run before the `StupidTask` (at least if they both are supposed to run at a given stepnumber)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aimmd.distributed\n",
    "from aimmd.distributed.pathmovers import MCstep  # only needed for the type hints\n",
    "\n",
    "\n",
    "class VerbosePrintTask(aimmd.dsitributed.pathsampling.BrainTask):\n",
    "    def __init__(self, interval: int = 1, name: str = \"VerbosePrintTask\"):\n",
    "        super().__init__(interval)\n",
    "        self._call_count = 0\n",
    "        self.name = name\n",
    "\n",
    "    def run(self, brain, mcstep: MCstep, sampler_idx: int):\n",
    "        # This will be called every `interval` finished Monte Carlo steps\n",
    "        self._call_count += 1  # increment call count to see how many times we call run\n",
    "        # We just print some basic info\n",
    "        print(f\"A sampler ({brain.samplers[sampler_idx]}) (index={sampler_idx}) \"\n",
    "              f\"attached to {brain} produced a Monte Carlo step ({mcstep}). \"\n",
    "              f\"This BrainTask with name {self.name} ({self}) got called for the {self._call_count}th time.\"\n",
    "              )\n",
    "\n",
    "\n",
    "class StupidTask(aimmd.distributed.pathsampling.BrainTask):\n",
    "    def __init__(self, interval: int = 1, p_cut: float = 0.5):\n",
    "        super().__init__(interval)\n",
    "        self.p_cut = p_cut\n",
    "\n",
    "    def run(self, brain, mcstep: MCstep, sampler_idx: int):\n",
    "        if mcstep.p_acc <= self.p_cut:\n",
    "            mcstep.accepted = False\n",
    "\n",
    "\n",
    "class MakeEveryStepAcceptedTask(aimmd.distributed.pathsampling.BrainTask):\n",
    "    def __init__(self, interval: int = 1):\n",
    "        super().__init__(interval)\n",
    "\n",
    "    def run(self, brain, mcstep: MCstep, sampler_idx: int):\n",
    "        if not mcstep.accepted:\n",
    "            # modify non-accepted steps to be accepted\n",
    "            # NOTE: this will (most likely) crash a sequential TPS simulation\n",
    "            #       because steps that are not accepted do not need to contain\n",
    "            #       a valid transition (i.e. their `path` attribute is not set)\n",
    "            #       so we can not start a new Monte Carlo step by shooting from\n",
    "            #       the last transition path\n",
    "            #       In a TPS simulation with equilibrium shooting points this\n",
    "            #       BrainTask will not have any effect becasue there every step\n",
    "            #       is formally accepted (and has an associated weight which\n",
    "            #       can be zero)\n",
    "            mcstep.accepted = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the TPS simulation\n",
    "\n",
    "This is the same setup as used in `TPS_1_setup_and_run_simulation.ipynb`, just with less comments and explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samplers\n",
    "n_samplers = 2  # results in 2*n_samplers gmx engines\n",
    "\n",
    "# storage file\n",
    "storage = aimmd.Storage(os.path.join(workdir, \"storage.h5\"))\n",
    "\n",
    "# state functions\n",
    "from state_funcs_mda import alpha_R, C7_eq\n",
    "wrapped_alphaR = asyncmd.trajectory.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "wrapped_C7_eq = asyncmd.trajectory.PyTrajectoryFunctionWrapper(C7_eq)\n",
    "\n",
    "# Underlying dynamics/ Define the engine(s) for the PathMovers (they will all be the same)\n",
    "gro = \"../gmx_infiles/conf.gro\"\n",
    "top = \"../gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"../gmx_infiles/index.ndx\"\n",
    "mdp = asyncgmx.MDP(\"gmx_infiles/md.mdp\")\n",
    "gmx_engine_kwargs = {\"mdconfig\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"output_traj_type\": \"XTC\",\n",
    "                     #\"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     \"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = asyncgmx.GmxEngine\n",
    "\n",
    "# initial transition\n",
    "tp_initial = Trajectory(structure_file=\"../gmx_infiles/ala_300K_amber99sb-ildn.tpr\",\n",
    "                        trajectory_files=\"../gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr\",\n",
    "                        )\n",
    "\n",
    "# descriptor transform\n",
    "# import descriptor_transform for the model\n",
    "# descriptor_func_ic gives us an internal coordinate representation (i.e. bond lengths, angles and dihedrals)\n",
    "from ..state_funcs_mda import descriptor_func_ic\n",
    "# and as usual wrapp them to become awaitable\n",
    "wrapped_transform = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_ic,\n",
    "                                                                   call_kwargs={\"molecule_selection\": \"protein\"},\n",
    "                                                                   )\n",
    "\n",
    "# Model definition\n",
    "# first get the descriptors for them to infer the number of inputs for our model\n",
    "descriptors_for_initial_tp = await wrapped_transform(tp_initial)\n",
    "# architecture specification\n",
    "n_lay_pyramid = 5  # number of resunits\n",
    "n_unit_top = 10  # number of units in the last layer before the log_predictor\n",
    "dropout_base = 0.3  # dropot fraction in the first layer (will be reduced going to the top)\n",
    "n_unit_base = cv_ndim = descriptors_for_initial_tp.shape[1]  # input dimension\n",
    "# the factor by which we reduce the number of units per layer (the width) and the dropout fraction\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "modules = []\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    modules += [aimmd.pytorch.networks.FFNet(n_in=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                             n_hidden=[max(n_unit_top, int(n_unit_base * fact**i))],  # 1 hidden layer network\n",
    "                                             activation=torch.nn.Identity(),\n",
    "                                             dropout={\"0\": dropout_base * fact**i}\n",
    "                                             )\n",
    "                ]\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i)))} units wide.\")\n",
    "    print(f\"Dropout before it is {dropout_base * fact**i}.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1, modules=modules)\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "# optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)\n",
    "# wrapp the pytorch neural network model in a RCModel class,\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,\n",
    "                                                            'lr_min': 5e-5,\n",
    "                                                            'epochs_per_train': 3,\n",
    "                                                            'window': 100,\n",
    "                                                            'batch_size': 8192,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_transform,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )\n",
    "\n",
    "# Define the TPS sampling scheme\n",
    "# shooting point selection\n",
    "spselector = aimmdd.spselectors.RCModelSPSelectorFromTraj()\n",
    "# and setup the movers lists (i.e. mover_cls and mover_kwargs for each sampler)\n",
    "# here we just use one move-type per sampler and therefore only have one entry\n",
    "# in each list\n",
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  #'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": spselector,\n",
    "                  \"max_steps\": 500 * 10**5,  # 500 steps * dt (2 fs) = 1 ps\n",
    "                  }\n",
    "                 ]\n",
    "\n",
    "# Trainset\n",
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize `BrainTask`s\n",
    "\n",
    "Here we will initialize our user-defined `BrainTask`s and also the basic `BrainTask`s needed for a TPS simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\n",
    "    # TrainingTask\n",
    "    aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "    # SaveTask\n",
    "    aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset),\n",
    "    # DensityCollectionTask\n",
    "    aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                              first_collection=100,\n",
    "                                              recreate_interval=250,\n",
    "                                              ),\n",
    "    # this task will print after every finished Monte Carlo step\n",
    "    VerbosePrintTask(interval=1, name=\"VerbosePrintTask_interval=1\"),\n",
    "    # this task will print only every 3rd finished Monte Carlo step\n",
    "    VerbosePrintTask(interval=3, name=\"VerbosePrintTask_interval=3\"),\n",
    "    # p_cut=100 should result in no accepted Monte Carlo steps as we will only\n",
    "    # accept steps that have p_acc >= 100\n",
    "    # (p_cut=0. would result in no modified Monte Carlo steps at all)\n",
    "    StupidTask(interval=1, p_cut=100.),\n",
    "    # uncomment the next line if you want to crash your TPS simulation :)\n",
    "    #MakeEveryStepAcceptedTask(interval=1),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the `Brain` (and attach the `BrainTask`s)\n",
    "\n",
    "Also seed the initial transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = aimmdd.Brain.samplers_from_moverlist(model=model, workdir=workdir, storage=storage,\n",
    "                                             n_sampler=n_samplers,\n",
    "                                             movers_cls=movers_cls, movers_kwargs=movers_kwargs,\n",
    "                                             samplers_use_same_stepcollection=False,\n",
    "                                             tasks=tasks)\n",
    "# seed initial transition for each Markov chain sampler\n",
    "brain.seed_initial_paths(trajectories=[tp_initial])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should call the second VerbosePrintTask 2 times and the first one 7 times\n",
    "await brain.run_for_n_steps(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the storage\n",
    "storage.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimmd_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
