{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gromacs engines\n",
    "This notebook showcases the use of the python classes used to steer gromacs from python. It will only work if the gromacs executables are available (e.g. in your `$PATH` variable).\n",
    "\n",
    "There are two main classes you will use together:\n",
    " - `aimmd.distributed.MDP`, a python class which parses a gromacs molecular dynamics parameter file (`.mdp`) and makes its content available via a dictionary-like interface\n",
    " - the `aimmd.distributed.GmxEngine` or the `aimmd.distributed.SlurmGmxEngine`, both share a common interface and are `aysnc/await` enabled python wrappers to run gromacs locally or via the SLURM workload manager, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and some basic checks that everything is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# if using the module system to make gromacs and friends available:\n",
    "# check that they are loaded!\n",
    "#module list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Modules/Data/gromacs/install/2020.0/bin/gmx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# unix only, check that gmx is available\n",
    "which gmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import MDAnalysis as mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aimmd\n",
    "import aimmd.distributed as aimmdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup working directory and the number of gromacs simulations to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_engines = 4\n",
    "\n",
    "#scratch_dir = \".\"\n",
    "scratch_dir = \"/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/\"\n",
    "#scratch_dir = \"/home/think/scratch/aimmd_distributed/\"\n",
    "wdirs = [os.path.join(scratch_dir, f\"engine_wdir{i}\") for i in range(n_engines)]\n",
    "\n",
    "for d in wdirs:\n",
    "    if not os.path.isdir(d):\n",
    "        os.mkdir(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `aimmd.distributed.GmxEngine` (and `aimmd.distributed.SlurmGmxEngine`)\n",
    "Both provide the functionality of the gromacs grompp and mdrun executables in one class, i.e. given molecular dynamics parameters and possibly an initial configuration they will setup and steer a MD run. Their interfaces differ only in the additional `sbatch_script` that the slurm engine requires at initialization time, they can otherwise be used interchangeably. Both engines need the gromacs executables to be available, specifically `gmx grompp` and `gmx mdrun`  (`gmx_mpi mdrun` for the `SlurmGmxEngine`). The `SlurmGmxEngine` naturally also must have access to the slurm executables, specifically `sbatch`, `sacct` and `scancel`. However all of these can be set either at initialization time via keyword arguments or globally as attributes to the uninitialized class.\n",
    "\n",
    "Each engine has a `prepare()` method (which will call `grompp`) and multiple methods to then run the simulation, namely `run()`, `run_walltime()` and `run_nsteps()`. The additional `prepare_from_files()` method can be used to continue a previous MD run from given `deffnm` and `workdir` (assuming all files/parts are there), note that it will (currently) not call `grompp` again and therefore assumes that the portable run input file (`.tpr`) allows for the continuation (i.e. has no or a sufficiently large integration step limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a list of identical engines to showcase the power of concurrent execution :)\n",
    "engines = [aimmdd.GmxEngine(gro_file=\"gmx_infiles/conf.gro\",  # required\n",
    "                            top_file=\"gmx_infiles/topol.top\",  # required\n",
    "                            ndx_file=\"gmx_infiles/index.ndx\",  # optional (can be omited or None), however naturally without an index file\n",
    "                                                               # you can not reference custom groups in the .mdp-file or MDP object \n",
    "                            # limit each engine to 2 threads (the box is so small that otherwise the domain decomposition fails)\n",
    "                            #mdrun_extra_args=\"-nt 2\",  # use this if your version of GMX is compiled with thread-MPI support\n",
    "                            mdrun_extra_args=\"-ntomp 2\",  # use this for GMX without thread-MPI support\n",
    "                            )\n",
    "           for _ in range(n_engines)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `aimmd.distributed.MDP`\n",
    "The `MDP` is a dictionary-like interface to a parsed gromacs molecular dynamics parameter file `.mdp` file to enable easy inspection and modification from python code. Most of the values are automatically cast to their respective types, e.g. `nsteps` will always be an `int` and `ref-t` will always be a list of `float`. The default for unknow parameters is a list of `str` to allow for the highest felxibility possible.\n",
    "\n",
    "The class supports writing of its (possibly changed) content to a new `.mdp` file by using its `.write()` method and also knows if its content has been changed since parsing the original `.mdp` file. It even supports the (undocumented) keyformat CHARMM-GUI uses in which all `-` are replaced by `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one MDP object per engine, in principal we could use the same object but this way is more customizable,\n",
    "# e.g. we could want to modify our setup have the engines run at a different temperatures\n",
    "mdps = [aimmdd.MDP(\"gmx_infiles/md.mdp\") for _ in range(n_engines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP has been changed since parsing:  False\n",
      "Parsed content:\n",
      "---------------\n",
      "title  :  ['test']\n",
      "cpp  :  ['/lib/cpp']\n",
      "include  :  ['-I../top']\n",
      "define  :  []\n",
      "integrator  :  ['md-vv']\n",
      "dt  :  0.002\n",
      "nsteps  :  -1\n",
      "nstxout  :  10\n",
      "nstvout  :  10\n",
      "nstlog  :  10\n",
      "nstenergy  :  10\n",
      "nstxout-compressed  :  10\n",
      "compressed-x-grps  :  ['Protein', 'SOL']\n",
      "energygrps  :  ['Protein', 'SOL']\n",
      "nstlist  :  10\n",
      "ns-type  :  ['grid']\n",
      "cutoff-scheme  :  ['Verlet']\n",
      "rlist  :  1.1\n",
      "coulombtype  :  ['PME']\n",
      "rcoulomb  :  1.1\n",
      "rvdw  :  1.1\n",
      "tcoupl  :  ['Berendsen']\n",
      "tc-grps  :  ['Protein', 'SOL']\n",
      "tau-t  :  [0.1, 0.1]\n",
      "ref-t  :  [300.0, 300.0]\n",
      "Pcoupl  :  ['Berendsen']\n",
      "tau-p  :  1.0\n",
      "compressibility  :  [4.5e-05]\n",
      "ref-p  :  [1.0]\n",
      "gen-vel  :  ['no']\n",
      "gen-temp  :  300.0\n",
      "gen-seed  :  173529\n",
      "constraints  :  ['all-bonds']\n",
      "lincs-iter  :  6\n"
     ]
    }
   ],
   "source": [
    "# lets have a look at what is inside\n",
    "print(\"MDP has been changed since parsing: \", mdps[0].changed)\n",
    "print(\"Parsed content:\")\n",
    "print(\"---------------\")\n",
    "for key, val in mdps[0].items():\n",
    "    print(key, \" : \", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets set the xtc output frequency to 0 in all MDPs, we will use the trr anyways\n",
    "# we will also increase the trr output frequency by a bit and add the `continuation` parameter\n",
    "nstout = 20\n",
    "for mdp in mdps:\n",
    "    mdp['nstvout'] = nstout\n",
    "    mdp[\"nstxout\"] = nstout\n",
    "    mdp[\"nstlog\"] = nstout\n",
    "    mdp[\"nstenergy\"] = nstout\n",
    "    mdp[\"nstxout-compressed\"] = 0\n",
    "    mdp[\"continuation\"] = \"yes\"  # dont apply constraints to the initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP has been changed since parsing:  True\n",
      "Parsed content:\n",
      "---------------\n",
      "title  :  ['test']\n",
      "cpp  :  ['/lib/cpp']\n",
      "include  :  ['-I../top']\n",
      "define  :  []\n",
      "integrator  :  ['md-vv']\n",
      "dt  :  0.002\n",
      "nsteps  :  -1\n",
      "nstxout  :  20\n",
      "nstvout  :  20\n",
      "nstlog  :  20\n",
      "nstenergy  :  20\n",
      "nstxout-compressed  :  0\n",
      "compressed-x-grps  :  ['Protein', 'SOL']\n",
      "energygrps  :  ['Protein', 'SOL']\n",
      "nstlist  :  10\n",
      "ns-type  :  ['grid']\n",
      "cutoff-scheme  :  ['Verlet']\n",
      "rlist  :  1.1\n",
      "coulombtype  :  ['PME']\n",
      "rcoulomb  :  1.1\n",
      "rvdw  :  1.1\n",
      "tcoupl  :  ['Berendsen']\n",
      "tc-grps  :  ['Protein', 'SOL']\n",
      "tau-t  :  [0.1, 0.1]\n",
      "ref-t  :  [300.0, 300.0]\n",
      "Pcoupl  :  ['Berendsen']\n",
      "tau-p  :  1.0\n",
      "compressibility  :  [4.5e-05]\n",
      "ref-p  :  [1.0]\n",
      "gen-vel  :  ['no']\n",
      "gen-temp  :  300.0\n",
      "gen-seed  :  173529\n",
      "constraints  :  ['all-bonds']\n",
      "lincs-iter  :  6\n",
      "continuation  :  ['yes']\n"
     ]
    }
   ],
   "source": [
    "# have a look again\n",
    "print(\"MDP has been changed since parsing: \", mdps[0].changed)\n",
    "print(\"Parsed content:\")\n",
    "print(\"---------------\")\n",
    "for key, val in mdps[0].items():\n",
    "    print(key, \" : \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have set the molecular dynamcis parameters we can prepare a gromacs MD run.\n",
    "The gromacs engines `prepare()` method will call grompp, as with grompp you can use a specific starting configuration (the grompp `-t` option) or start the structure file (`.gro`) the engine got at initialization.\n",
    "\n",
    "### Lets prepare the first engine without a starting structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "e0 = engines[0]  # get it out of the list so tab-help/completion works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prepare method is an async def function (a coroutine) and must be awaited\n",
    "await e0.prepare(starting_configuration=None, workdir=wdirs[0], deffnm=\"test\", run_config=mdps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets prepare all other engines at once with the same initial configuration\n",
    "We can use asyncio.gather to run all coroutines concurrently, for prepare this does not make a big difference (since it is fast), but the same mechanism enables us to run all 4 gromacs engines in parallel later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an aimmd.distributed.Trajectory of the initial configuration\n",
    "init_conf = aimmdd.Trajectory(trajectory_file=\"gmx_infiles/conf.trr\",\n",
    "                              structure_file=\"gmx_infiles/conf.gro\",\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and prepare the engines (the return value of prepare is None)\n",
    "await asyncio.gather(*(e.prepare(starting_configuration=init_conf, workdir=wdir, deffnm=\"test\", run_config=mdp)\n",
    "                       for e, wdir, mdp in zip(engines[1:], wdirs[1:], mdps[1:])\n",
    "                       )\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run the engines for a number of steps each.\n",
    "We will first run the last engine in the list alone and then all 4 concurrently for the same number of steps to show off the power of the concurrent execution of the gromacs subprocesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # import time to be able to show off ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one engine for 100000 integration steps took 74.248 seconds.\n",
      "The produced trajectory (Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir3/test.part0001.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir3/test.tpr)) has a length of 5001 frames.\n",
      "This length is the number of steps divided by the engines output frequency (=20).\n",
      "Note, that we are off by plus one because the initial configuration is in the trajectory for gromacs.\n",
      "Note also that this is only true when explicitly passing nsteps to the `run` methods, unfortunately the real relation between frames\n",
      "and steps done is a bit more involved...See the docstring for `GmxEngine.steps_done` if you are brave and want to know more ;)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    }
   ],
   "source": [
    "nsteps = 100000\n",
    "\n",
    "# run one engine and time it\n",
    "start = time.time()\n",
    "# the engine will return an aimmd.distributed.Trajectory with the produced trajectory (part)\n",
    "traj = await engines[-1].run_steps(nsteps=nsteps, steps_per_part=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running one engine for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"The produced trajectory ({traj}) has a length of {len(traj)} frames.\")\n",
    "print(f\"This length is the number of steps divided by the engines output frequency (={engines[-1].nstout}).\")\n",
    "print(\"Note, that we are off by plus one because the initial configuration is in the trajectory for gromacs.\")\n",
    "print(\"Note also that this is only true when explicitly passing nsteps to the `run` methods, unfortunately the real relation between frames\")\n",
    "print(\"and steps done is a bit more involved...See the docstring for `GmxEngine.steps_done` if you are brave and want to know more ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajs_engine3 = [traj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 100000 integration steps took 77.9275 seconds.\n",
      "But now we have a list of 4 trajectories with 100000 steps each...\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir0/test.part0001.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir0/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir1/test.part0001.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir1/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir2/test.part0001.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir2/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir3/test.part0002.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir3/test.tpr)  with length: 5001\n"
     ]
    }
   ],
   "source": [
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "# Now each engine will return an aimmd.distributed.Trajectory with the produced trajectory (part)\n",
    "# i.e. trajs will be a list of trajectories (in the same order as the engines in the list)\n",
    "trajs = await asyncio.gather(*(e.run_steps(nsteps=nsteps, steps_per_part=True) for e in engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {nsteps} integration steps took {round(end - start, 4)} seconds.\")\n",
    "print(f\"But now we have a list of {len(trajs)} trajectories with {nsteps} steps each...\")\n",
    "for t in trajs:\n",
    "    print(t, f\" with length: {len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajs_engine3 += [trajs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `prepare_from_files` to initialize new engines and pick up where we left off with the 'old' ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the engines\n",
    "new_engines = [aimmdd.GmxEngine(gro_file=\"gmx_infiles/conf.gro\",\n",
    "                                top_file=\"gmx_infiles/topol.top\",\n",
    "                                ndx_file=\"gmx_infiles/index.ndx\",\n",
    "                                #mdrun_extra_args=\"-nt 2\",  # use this if your version of GMX is compiled with thread-MPI support\n",
    "                                mdrun_extra_args=\"-ntomp 2\",  # use this for GMX without thread-MPI support\n",
    "                                )\n",
    "               for _ in range(n_engines)]\n",
    "e0 = new_engines[0]  # get one out for the autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and initialize with prepare_from_files\n",
    "await e0.prepare_from_files(workdir=wdirs[0], deffnm=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the others concurrent in one go\n",
    "await asyncio.gather(*(e.prepare_from_files(workdir=wdir, deffnm=\"test\") for e, wdir in zip(new_engines[1:], wdirs[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can do another round of MD in all engines in parallel\n",
    "Note that the partnums indicate that we picked up exactly where we left of. We could additionally check using the trajectories `.last_step` and `.first_step` properties, compare and observe that the last step in the previous MD runs will be the first step in these here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 100000 integration steps took 77.3013505935669 seconds.\n",
      "But now we have a list of 4 trajectories with 100000 steps each...\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir0/test.part0002.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir0/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir1/test.part0002.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir1/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir2/test.part0002.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir2/test.tpr)  with length: 5001\n",
      "Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir3/test.part0003.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir3/test.tpr)  with length: 5001\n"
     ]
    }
   ],
   "source": [
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "trajs = await asyncio.gather(*(e.run_steps(nsteps=nsteps, steps_per_part=True) for e in new_engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {nsteps} integration steps took {end - start} seconds.\")\n",
    "print(f\"But now we have a list of {len(trajs)} trajectories with {nsteps} steps each...\")\n",
    "for t in trajs:\n",
    "    print(t, f\" with length: {len(t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajs_engine3 += [trajs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for specified walltime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all engines for 0.01 h (=36.0 s) took 38.7215 seconds.\n"
     ]
    }
   ],
   "source": [
    "walltime = 0.01 # 0.01 h = 36 s\n",
    "\n",
    "# run all engines at once and time it\n",
    "start = time.time()\n",
    "trajs = await asyncio.gather(*(e.run_walltime(walltime) for e in new_engines))\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Running all engines for {walltime} h (={walltime*60*60} s) took {round(end - start, 4)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajs_engine3 += [trajs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for specified walltime or number of steps (depending on what is reached first)\n",
    "We can also use the generic `run()` method which takes one or both of the `walltime` and `nsteps` arguments, it will finish as soon as one of the conditions is fullfilled. As the `run_steps()` method it also accepts the `steps_per_part` argument making it particularly useful to run in chunks (of length walltime) but for a fixed total number of steps.\n",
    "\n",
    "Note that we can either check if `engine.steps_done < n_steps_desired` (as we do below) or call the `engine.run(nsteps=n_steps_desired)` method until it returns `None` instead of a trajectory object, which indicates that the total number of steps done in that engine is exactly the requested number of total steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247840, 248320, 248160, 348240]\n",
      "[True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([e.steps_done for e in new_engines])\n",
    "print([e.steps_done < (max([e.steps_done for e in new_engines]) + 20000) for e in new_engines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n",
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n",
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/topology/tpr/utils.py:389: DeprecationWarning: TPR files index residues from 0. From MDAnalysis version 2.0, resids will start at 1 instead. If you wish to keep indexing resids from 0, please set `tpr_resid_from_one=False` as a keyword argument when you create a new Topology or Universe.\n",
      "  warnings.warn(\"TPR files index residues from 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran for a total of 3 loops. It took us 92.8987 seconds.\n"
     ]
    }
   ],
   "source": [
    "walltime = 0.01 # 0.01 h = 36 s\n",
    "nsteps = max([e.steps_done for e in new_engines]) + 20000\n",
    "\n",
    "all_trajs = []\n",
    "all_times = []\n",
    "while any([e.steps_done < nsteps for e in new_engines]):\n",
    "    # run all engines at once and time it\n",
    "    start = time.time()\n",
    "    trajs = await asyncio.gather(*(e.run(walltime=walltime, nsteps=nsteps, steps_per_part=False) for e in new_engines))\n",
    "    end = time.time()\n",
    "    all_trajs.append(trajs)\n",
    "    all_times.append(end-start)\n",
    "\n",
    "print(f\"Ran for a total of {len(all_times)} loops. It took us {round(sum(all_times), 4)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir0/test.part0006.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir0/test.tpr),\n",
       " Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir1/test.part0006.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir1/test.tpr),\n",
       " Trajectory(trajectory_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir2/test.part0006.trr, structure_file=/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/engine_wdir2/test.tpr),\n",
       " None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the last engine will probably already have produced a `None` instead of a trajectory in the last iteration\n",
    "# (since it is some steps ahead of the others because we ran it alone at the beginning of the notebook)\n",
    "all_trajs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trajs in all_trajs:\n",
    "    if trajs[3] is not None:\n",
    "        all_trajs_engine3 += [trajs[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_funcs_mda import C7_eq, alpha_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "C7_eq_wrapped = aimmdd.PyTrajectoryFunctionWrapper(C7_eq)\n",
    "# the optional call_kwargs argument can be used to specify additional keyword arguments\n",
    "# [we pass skip=1 which does not do anything because it is the default value only to show that call_kwargs exists]\n",
    "alpha_R_wrapped = aimmdd.PyTrajectoryFunctionWrapper(alpha_R, call_kwargs={\"skip\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory with idx 0 has first step 0, last step 100000 and length 5001 frames.\n",
      "First timestep 0.0; last timestep 200.0.\n",
      "Trajectory with idx 1 has first step 100000, last step 200000 and length 5001 frames.\n",
      "First timestep 200.0; last timestep 400.0.\n",
      "Trajectory with idx 2 has first step 200000, last step 300000 and length 5001 frames.\n",
      "First timestep 400.0; last timestep 600.0.\n",
      "Trajectory with idx 3 has first step 300000, last step 348240 and length 2413 frames.\n",
      "First timestep 600.0; last timestep 696.47998046875.\n",
      "Trajectory with idx 4 has first step 348240, last step 368240 and length 1001 frames.\n",
      "First timestep 696.47998046875; last timestep 736.47998046875.\n"
     ]
    }
   ],
   "source": [
    "C7_vals = []\n",
    "alpha_vals = []\n",
    "for i, t in enumerate(all_trajs_engine3):\n",
    "    print(f\"Trajectory with idx {i} has first step {t.first_step}, last step {t.last_step} and length {len(t)} frames.\")\n",
    "    print(f\"First timestep {t.first_time}; last timestep {t.last_time}.\")\n",
    "    C7, alpha = await asyncio.gather(*(C7_eq_wrapped(t), alpha_R_wrapped(t)))\n",
    "    C7_vals += [C7]\n",
    "    alpha_vals += [alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimmd.distributed.trajectory import TrajectoryConcatenator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenator = TrajectoryConcatenator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_for_bw = [(len(t), None, -1) for t in all_trajs_engine3[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1001, None, -1),\n",
       " (2413, None, -1),\n",
       " (5001, None, -1),\n",
       " (5001, None, -1),\n",
       " (5001, None, -1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices_for_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inverted = concatenator.concatenate(trajs=all_trajs_engine3[::-1],\n",
    "                                         slices=slices_for_bw,\n",
    "                                         tra_out=\"inverted.trr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_nature_publish/lib/python3.8/site-packages/MDAnalysis/coordinates/XDR.py:216: UserWarning: Reload offsets from trajectory\n",
      " ctime or size or n_atoms did not match\n",
      "  warnings.warn(\"Reload offsets from trajectory\\n \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18413"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traj_inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_inverted.first_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_inverted.last_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736.47998046875\n",
      "0.0\n",
      "-0.03997802734375\n"
     ]
    }
   ],
   "source": [
    "print(traj_inverted.first_time)\n",
    "print(traj_inverted.last_time)\n",
    "print(traj_inverted.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [(0, None, 1) for _ in range(len(all_trajs_engine3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated = concatenator.concatenate(trajs=all_trajs_engine3,\n",
    "                                        slices=slices,\n",
    "                                        tra_out=\"concatenated.trr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18413"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated.first_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated.last_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "736.47998046875\n",
      "0.03999999910593033\n"
     ]
    }
   ],
   "source": [
    "print(concatenated.first_time)\n",
    "print(concatenated.last_time)\n",
    "print(concatenated.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 736.4000244140625, 'step': 998, 'lambda': 0.0, 'dt': -0.03997802734375}\n"
     ]
    }
   ],
   "source": [
    "ui = mda.Universe(traj_inverted.structure_file, traj_inverted.trajectory_file)\n",
    "ts = ui.trajectory[2]\n",
    "print(ts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 736.4000244140625, 'step': 998, 'lambda': 0.0, 'dt': 0.03999999910593033}\n"
     ]
    }
   ],
   "source": [
    "uc = mda.Universe(concatenated.structure_file, concatenated.trajectory_file)\n",
    "ts = uc.trajectory[-3]\n",
    "print(ts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "C7_for_concat, alpha_for_concat = await asyncio.gather(*(C7_eq_wrapped(concatenated), alpha_R_wrapped(concatenated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "C7_for_invert, alpha_for_invert = await asyncio.gather(*(C7_eq_wrapped(traj_inverted), alpha_R_wrapped(traj_inverted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18417"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(t) for t in all_trajs_engine3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-e118bd9eb030>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  axs.plot(np.concatenate(C7_vals, dtype=np.int) - np.asarray(C7_for_concat, dtype=np.int), label=\"traj parts\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (18417,) (18413,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e118bd9eb030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#axs.plot(C7_for_concat, label=\"concat\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#axs.plot(C7_for_invert[::-1], label=\"invert\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC7_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC7_for_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"traj parts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (18417,) (18413,) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots()\n",
    "\n",
    "#axs.plot(C7_for_concat, label=\"concat\")\n",
    "#axs.plot(C7_for_invert[::-1], label=\"invert\")\n",
    "axs.plot(np.concatenate(C7_vals, dtype=np.int) - np.asarray(C7_for_concat, dtype=np.int), label=\"traj parts\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "{'time': 200.0, 'step': 100000, 'lambda': 0.0, 'dt': 0.03999999910593033}\n"
     ]
    }
   ],
   "source": [
    "u0 = mda.Universe(all_trajs_engine3[0].structure_file, all_trajs_engine3[0].trajectory_file)\n",
    "ts = u0.trajectory[-1]\n",
    "print(ts.data[\"step\"])\n",
    "print(ts.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "{'time': 200.0, 'step': 100000, 'lambda': 0.0, 'dt': 0.0399932861328125}\n"
     ]
    }
   ],
   "source": [
    "u1 = mda.Universe(all_trajs_engine3[1].structure_file, all_trajs_engine3[1].trajectory_file)\n",
    "ts = u1.trajectory[0]\n",
    "print(ts.data[\"step\"])\n",
    "print(ts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMMD nature publish (py3)",
   "language": "python",
   "name": "aimmd_nature_publish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
