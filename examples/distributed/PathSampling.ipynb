{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massively parallel Transition Path Sampling\n",
    "\n",
    "## Notebook 1: Run TPS simulation\n",
    "\n",
    "This is the first of a series of example notebooks on massively parallel transition path sampling. We will use multiple samplers (each generating its own Markov chain) that are all steered by one central reaction coordinate model. This has the benefit that the central model learns from all chains/samplers, which is more time efficient since we can run all samplers at the same time (e.g. on an HPC cluster). And since the chains will diverge from each other the central model will also see multiple reaction mechanisms at the same time, i.e. it will learn all of them. Since all chains have equal weight you can still easily calculate ensemble averages over the transition path ensemble by weighting each Monte carlo state in each chain with equal weight. Note, that to start the sampling we do need an initial transition for each sampler/Markov chain (as opposed to TPS from equilibrium points). If you use different initial transitions for each sampler this is actually a benefit as it enables you to estimate if the ensemble is converged by comparing the chains to each other (which you will see in the analysis notebook).\n",
    "\n",
    "In this notebook we will use capped alanine dipetide as our example molecule and look at the transition between $C7_{eq}$ and $\\alpha_R$ states. We will use the locally running `GmxEngine` and `PyTrajectoryFunctionWrapper` classes (such that you can run it on your workstation), but you can easily perform a massively parallel TPS on a HPC cluster running SLURM by using the `SlurmGmxEngine` and `SlurmTrajectoryFunctionWrapper` classes instead. However, in that case you will probably want to use a larger (and more interessting) system than capped alanine dipeptide :)\n",
    "\n",
    "**This notebook should be run on a multi-core workstation preferably with a GPU**, otherwise you will have a very long coffee break and a very hot laptop.\n",
    "\n",
    "**Required knowledge/recommended reading:** This notebooks assumes some familarity with the `asyncmd` (namely the [gromacs] engine and TrajectoryFunctionWrapper classes). Please see the example notebooks in `asyncmd` for an introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/hejung/.conda/envs/aimmd_distributed_devel/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Could not initialize SLURM cluster handling. If you are sure SLURM (sinfo/sacct/etc) is available try calling `asyncmd.config.set_slurm_settings()` with the appropriate arguments.\n",
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import mdtraj as mdt\n",
    "import MDAnalysis as mda\n",
    "import asyncmd\n",
    "import asyncmd.gromacs as asyncgmx\n",
    "from asyncmd import Trajectory\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "\n",
    "scratch_dir = \"/homeloc/scratch/aimmd_distributed/\"\n",
    "#scratch_dir = \".\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"TransitionPathSampling_ala\")\n",
    "\n",
    "if not os.path.isdir(workdir):\n",
    "    os.mkdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# executing this file sets the variable LOGCONFIG, which is a dictionary of logging presets \n",
    "%run ../resources/logconf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 'WARN', 'handlers': ['stdf', 'warnout']}\n",
      "{'level': 'INFO'}\n",
      "{'class': 'logging.FileHandler', 'level': 'INFO', 'mode': 'w', 'filename': 'simulation.log', 'formatter': 'standardFormatter'}\n"
     ]
    }
   ],
   "source": [
    "# have a look at the default logging level (the level used for the root logger)\n",
    "print(LOGCONFIG[\"loggers\"][\"\"])\n",
    "# have a look at the logger for aimmd\n",
    "print(LOGCONFIG[\"loggers\"][\"aimmd\"])\n",
    "# and have a look at the log-level for the filehandler\n",
    "print(LOGCONFIG[\"handlers\"][\"stdf\"])\n",
    "# the last two should both be `INFO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: more logging to file\n",
    "level = \"INFO\"\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"level\"] = level\n",
    "LOGCONFIG[\"loggers\"][\"aimmd\"][\"level\"] = level\n",
    "LOGCONFIG[\"loggers\"][\"asyncmd\"] = {\"level\": level}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can either modify single values or use it as is to get the same setup as in the OPS default logging config file\n",
    "# you could e.g. do LOGCONF['handlers']['stdf']['filename'] = new_name to change the filename of the log\n",
    "# the default is to create 'simulation.log' and 'initialization.log' in the current working directory\n",
    "import logging.config\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"filename\"] = os.path.join(workdir, \"simulation_pathsampling.log\")\n",
    "LOGCONFIG[\"handlers\"][\"initf\"][\"filename\"] = os.path.join(workdir, \"initlog_pathsampling.log\")\n",
    "logging.config.dictConfig(LOGCONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now the actual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samplers = 5  # results in 2*n_samplers gmx engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = aimmd.Storage(os.path.join(workdir, \"storage.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine(s) for the PathMovers\n",
    "# (they will all be the same)\n",
    "gro = \"gmx_infiles/conf.gro\"\n",
    "top = \"gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"gmx_infiles/index.ndx\"\n",
    "mdp = asyncgmx.MDP(\"gmx_infiles/md.mdp\")\n",
    "\n",
    "gmx_engine_kwargs = {\"mdconfig\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"output_traj_type\": \"XTC\",\n",
    "                     #\"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     \"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = asyncgmx.GmxEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state functions\n",
    "from state_funcs_mda import alpha_R, C7_eq\n",
    "\n",
    "wrapped_alphaR = asyncmd.trajectory.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "\n",
    "wrapped_C7_eq = asyncmd.trajectory.PyTrajectoryFunctionWrapper(C7_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptor_transform for the model\n",
    "\n",
    "# internal coordinates\n",
    "from state_funcs_mda import descriptor_func_ic\n",
    "\n",
    "wrapped_transform = asyncmd.trajectory.PyTrajectoryFunctionWrapper(descriptor_func_ic, call_kwargs={\"molecule_selection\": \"protein\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial transitions\n",
    "tp_lb = Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_files=\"gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr\")\n",
    "tp_short = Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_files=\"gmx_infiles/TP_short_low_barrier_300K_amber99sbildn.trr\")\n",
    "tp_short2 = Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_files=\"gmx_infiles/TP_short2_low_barrier_300K_amber99sbildn.trr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 18, 28]\n"
     ]
    }
   ],
   "source": [
    "print([len(tp) for tp in [tp_lb, tp_short, tp_short2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the descriptors for one of them to infer the number of inputs for our model\n",
    "descriptors_for_tp = await wrapped_transform(tp_lb)\n",
    "descriptors_for_tp_short = await wrapped_transform(tp_short)\n",
    "descriptors_for_tp_short2 = await wrapped_transform(tp_short2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await wrapped_alphaR(tp_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await wrapped_C7_eq(tp_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for model\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit 1 is 66 units wide.\n",
      "Dropout before it is 0.18674307214231128.\n",
      "ResUnit 2 is 41 units wide.\n",
      "Dropout before it is 0.1162432499771616.\n",
      "ResUnit 3 is 25 units wide.\n",
      "Dropout before it is 0.07235873872180604.\n",
      "ResUnit 4 is 16 units wide.\n",
      "Dropout before it is 0.045041643884176266.\n",
      "ResUnit 5 is 10 units wide.\n",
      "Dropout before it is 0.02803738317757008.\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "n_lay_pyramid = 5\n",
    "n_unit_top = 10\n",
    "dropout_base = 0.3\n",
    "n_unit_base = cv_ndim = descriptors_for_tp.shape[1]\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "modules = []\n",
    "\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    #print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i-1)))} units wide.\")\n",
    "    #modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "    #                                          n_blocks=1)\n",
    "    #            ]\n",
    "\n",
    "    modules += [aimmd.pytorch.networks.FFNet(n_in=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                             n_hidden=[max(n_unit_top, int(n_unit_base * fact**i))],  # 1 hidden layer network\n",
    "                                             activation=torch.nn.Identity(),\n",
    "                                             dropout={\"0\": dropout_base * fact**i}\n",
    "                                             )\n",
    "                ]\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i)))} units wide.\")\n",
    "    print(f\"Dropout before it is {dropout_base * fact**i}.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\n",
    "                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\n",
    "                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\n",
    "                                                 modules=modules,  # modules is a list of initialized torch.nn.Modules from arcd.pytorch.networks\n",
    "                                                 )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "\n",
    "# choose and initialize an optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take an ExpectedEfficiencyPytorchRCModel,\n",
    "# this RCmodel scales the learning rate by the expected efficiency factor (1 - n_TP_true / n_TP_expected)**2\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,  \n",
    "                                                            #'lr_min': 5e-5,  # lr_min = lr_0 / 20 is a good choice empirically\n",
    "                                                            'lr_min': 5e-5,\n",
    "                                                            'epochs_per_train': 3, # try 5, [10 and 15] next\n",
    "                                                            #'epochs_per_train': 5,\n",
    "                                                            'interval': 5,\n",
    "                                                            #'interval': 10,\n",
    "                                                            #'window': 75,\n",
    "                                                            'window': 100,\n",
    "                                                            'batch_size': 8192,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_transform,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use a list with initialized movers\n",
    "#movers = [[aimmdd.TwoWayShootingPathMover(states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "#                                          engine_cls=gmx_engine_cls,\n",
    "#                                          engine_kwargs=gmx_engine_kwargs,\n",
    "#                                          engine_config=mdp,\n",
    "#                                          walltime_per_part=0.01,\n",
    "#                                          T=mdp[\"ref-t\"][0],\n",
    "#                                         )\n",
    "#           ] for i in range(n_samplers)\n",
    "#         ]\n",
    "\n",
    "# it is easier though to use the `Brain.chains_from_moverlist()` function\n",
    "# this function will create n-chain identical PathSamplingChains where the movers for each chain are\n",
    "# specified by movers_cls (a list of mover classes) and movers_kwargs (a dict with keyword arguments used for initialization of the movers)\n",
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  # NOTE: choose this as short as possible!\n",
    "                  #       since ala is super-small and commits fast we should make sure\n",
    "                  #       that most trials reach a state in the first part\n",
    "                  #       this in turn makes sure that we do not call gromasc multiple times per trial (saving setup time)\n",
    "                  #       but still ensures that the resulting trajectories are not too long and large\n",
    "                  #       it also reduces the time needed per step (we need at least walltime_per_part hours per step)\n",
    "                  #'walltime_per_part': 0.000015625,  # 0.055125 s per part\n",
    "                  'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  #'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  #'walltime_per_part': 0.000125,  # 0.45 s per part\n",
    "                  #'walltime_per_part': 0.00025,  # 0.9 s per part\n",
    "                  #'walltime_per_part': 0.0005,  # 1.8 s per part\n",
    "                  #'walltime_per_part': 0.001,  # 3.6 s per part\n",
    "                  #'walltime_per_part': 0.002,  # 7.2 s per part\n",
    "                  #'walltime_per_part': 0.003,  # 10.8 s per part\n",
    "                  #'walltime_per_part': 0.004,  # 14.4 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": aimmdd.spselectors.RCModelSPSelectorFromTraj(),  # can be used to customize SP-selection params \n",
    "                  \"max_steps\": 500 * 10**5,  # 500 steps * dt (2 fs) = 1 ps\n",
    "                  }\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "         aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset),\n",
    "         aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                                   first_collection=100,\n",
    "                                                   recreate_interval=250,\n",
    "                                                   interval=10\n",
    "                                                   ),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this would be the full __init__ call to the brain\n",
    "# it gives you full flexibility of setting up every PathSamplingChain individually\n",
    "#brain = aimmdd.Brain(model=model, workdir=workdir, storage=storage, movers=movers, mover_weights=[[1.], [1.], [1.]], tasks=tasks)\n",
    "\n",
    "# this is the 'easy' way\n",
    "brain = aimmdd.Brain.samplers_from_moverlist(model=model, workdir=workdir, storage=storage,\n",
    "                                             n_sampler=n_samplers,\n",
    "                                             movers_cls=movers_cls, movers_kwargs=movers_kwargs,\n",
    "                                             samplers_use_same_stepcollection=False,\n",
    "                                             tasks=tasks)\n",
    "                                           # Note that we left mover_weights=None at its default, this results\n",
    "                                           # in uniform weights for all movers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler 0:  None\n",
      "\n",
      "Sampler 1:  None\n",
      "\n",
      "Sampler 2:  None\n",
      "\n",
      "Sampler 3:  None\n",
      "\n",
      "Sampler 4:  None\n",
      "\n",
      "Sampler 0: \n",
      "MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles), with path Trajectory(trajectory_files=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr, structure_file=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Sampler 1: \n",
      "MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles), with path Trajectory(trajectory_files=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/TP_short_low_barrier_300K_amber99sbildn.trr, structure_file=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Sampler 2: \n",
      "MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles), with path Trajectory(trajectory_files=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/TP_short2_low_barrier_300K_amber99sbildn.trr, structure_file=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Sampler 3: \n",
      "MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles), with path Trajectory(trajectory_files=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr, structure_file=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Sampler 4: \n",
      "MCStep(mover=None, stepnum=0, states_reached=None, accepted=True, p_acc=1, predicted_committors_sp=None, weight=1,\n",
      "       directory=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles), with path Trajectory(trajectory_files=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/TP_short_low_barrier_300K_amber99sbildn.trr, structure_file=/home/tb/hejung/Documents/sources/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: old cumbersome setup\n",
    "\n",
    "#initial_step = aimmdd.logic.MCstep(mover=None, stepnum=0, directory=\"gmx_infiles\", path=tp_short, accepted=True)\n",
    "#initial_step2 = aimmdd.logic.MCstep(mover=None, stepnum=0, directory=\"gmx_infiles\", path=tp_long, accepted=True)\n",
    "\n",
    "# take two different initial TPs\n",
    "#for i, c in enumerate(brain.chains):\n",
    "#    if i == 2:\n",
    "#        c.current_step = initial_step2\n",
    "#        c.chainstore.append(initial_step2)  # save the initial step as first step of every chain\n",
    "#    else:\n",
    "#        c.current_step = initial_step\n",
    "#        c.chainstore.append(initial_step)  # save the initial step as first step of every chain\n",
    "\n",
    "\n",
    "# NEW: use the new seed_initial_paths() method!\n",
    "# have a look at before\n",
    "for i, s in enumerate(brain.samplers):\n",
    "    print(f\"Sampler {i}: \", s.current_step)\n",
    "    print()\n",
    "# seed them\n",
    "brain.seed_initial_paths(trajectories=[tp_lb, tp_short, tp_short2], weights=[1., 1., 1.])\n",
    "# have a look again\n",
    "for i, s in enumerate(brain.samplers):\n",
    "    print(f\"Sampler {i}: \")\n",
    "    print(f\"{s.current_step}, with path {s.current_step.path}.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 10000 cummulative MCSteps took 18214.41458582878 s (= 303.5735764304797 min).\n"
     ]
    }
   ],
   "source": [
    "n_steps = 10000\n",
    "start = time.time()\n",
    "\n",
    "await brain.run_for_n_steps(n_steps)\n",
    "#await brain.run_for_n_steps(2000)\n",
    "#await brain.run_for_n_accepts(25)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Running for {n_steps} cummulative MCSteps took {end-start} s (= {(end-start)/60} min).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the last model, trainset and brain to storage\n",
    "This enables us to do the analysis in a different notebook and/or continue the TPS simulation from the last step easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the last model\n",
    "storage.rcmodels[\"model_to_continue_with\"] = model\n",
    "storage.save_trainset(trainset)\n",
    "storage.save_brain(brain)\n",
    "# TODO: explain that the SaveTask saves everything too (but only at the specified intervals, os best to save yourself at the end to be sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimmd distributed devel (py3.9 with asyncmd)",
   "language": "python",
   "name": "aimmd_distributed_devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
