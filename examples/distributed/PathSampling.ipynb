{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mdtraj as mdt\n",
    "import MDAnalysis as mda\n",
    "import aimmd\n",
    "import aimmd.distributed as aimmdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup working directory\n",
    "\n",
    "#scratch_dir = \".\"\n",
    "#scratch_dir = \"/home/tb/hejung/DATA/aimmd_scratch/aimmd_distributed/\"\n",
    "scratch_dir = \"/home/think/scratch/aimmd_distributed/\"\n",
    "\n",
    "workdir = os.path.join(scratch_dir, \"PathSampling_mda_test\")\n",
    "\n",
    "if not os.path.isdir(workdir):\n",
    "    os.mkdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "# executing this file sets the variable LOGCONFIG, which is a dictionary of logging presets \n",
    "%run ../resources/logconf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 'WARN', 'handlers': ['stdf', 'warnout']}\n",
      "{'level': 'INFO'}\n",
      "{'class': 'logging.FileHandler', 'level': 'INFO', 'mode': 'w', 'filename': 'simulation.log', 'formatter': 'standardFormatter'}\n"
     ]
    }
   ],
   "source": [
    "# have a look at the default logging level (the level used for the root logger)\n",
    "print(LOGCONFIG[\"loggers\"][\"\"])\n",
    "# have a look at the logger for aimmd\n",
    "print(LOGCONFIG[\"loggers\"][\"aimmd\"])\n",
    "# and have a look at the log-level for the filehandler\n",
    "print(LOGCONFIG[\"handlers\"][\"stdf\"])\n",
    "# the last two should both be `INFO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: more logging\n",
    "#LOGCONFIG[\"handlers\"][\"stdf\"][\"level\"] = \"DEBUG\"\n",
    "#LOGCONFIG[\"loggers\"][\"aimmd\"][\"level\"] = \"DEBUG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can either modify single values or use it as is to get the same setup as in the OPS default logging config file\n",
    "# you could e.g. do LOGCONF['handlers']['stdf']['filename'] = new_name to change the filename of the log\n",
    "# the default is to create 'simulation.log' and 'initialization.log' in the current working directory\n",
    "import logging.config\n",
    "LOGCONFIG[\"handlers\"][\"stdf\"][\"filename\"] = os.path.join(workdir, \"simulation_pathsampling.log\")\n",
    "LOGCONFIG[\"handlers\"][\"initf\"][\"filename\"] = os.path.join(workdir, \"initlog_pathsampling.log\")\n",
    "logging.config.dictConfig(LOGCONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now the actual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 4  # results in 2*n_chains gmx engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = aimmd.Storage(os.path.join(workdir, \"storage.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the engine(s) for the PathMovers\n",
    "# (they will all be the same)\n",
    "gro = \"gmx_infiles/conf.gro\"\n",
    "top = \"gmx_infiles/topol_amber99sbildn.top\"\n",
    "ndx = \"gmx_infiles/index.ndx\"\n",
    "mdp = aimmdd.MDP(\"gmx_infiles/md.mdp\")\n",
    "\n",
    "#gro = \"../capped_alanine_dipeptide/conf.gro\"\n",
    "#top = \"../capped_alanine_dipeptide/topol.top\"\n",
    "#ndx = None\n",
    "#mdp = aimmdd.MDP(\"../capped_alanine_dipeptide/md.mdp\")\n",
    "\n",
    "\n",
    "gmx_engine_kwargs = {\"mdp\": mdp,\n",
    "                     \"gro_file\": gro,\n",
    "                     \"top_file\": top,\n",
    "                     \"ndx_file\": ndx,\n",
    "                     \"mdrun_extra_args\": \"-nt 2\",\n",
    "                     # use this for gmx sans (thread) MPI\n",
    "                     #\"mdrun_extra_args\": \"-ntomp 2\",\n",
    "                     }\n",
    "gmx_engine_cls = aimmdd.GmxEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state functions\n",
    "from state_funcs_mda import alpha_R, C7_eq\n",
    "\n",
    "wrapped_alphaR = aimmdd.PyTrajectoryFunctionWrapper(alpha_R)\n",
    "\n",
    "wrapped_C7_eq = aimmdd.PyTrajectoryFunctionWrapper(C7_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptor_transform for the model\n",
    "\n",
    "# internal coordinates\n",
    "from state_funcs_mda import descriptor_func_ic\n",
    "\n",
    "wrapped_transform = aimmdd.PyTrajectoryFunctionWrapper(descriptor_func_ic, call_kwargs={\"molecule_selection\": \"protein\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load initial transitions\n",
    "#tp_lb = aimmdd.Trajectory(structure_file=\"../capped_alanine_dipeptide/ala_md_300K.tpr\",\n",
    "#                          trajectory_file=\"../capped_alanine_dipeptide/ala_300K_TP_low_barrier_gmx_engine.trr\")\n",
    "tp_lb = aimmdd.Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_file=\"gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr\")\n",
    "#tp_short = aimmdd.Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_file=\"gmx_infiles/ala_300K_TP.trr\")\n",
    "#tp2_short = aimmdd.Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_file=\"gmx_infiles/ala_300K_TP2.trr\")\n",
    "#tp_long = aimmdd.Trajectory(structure_file=\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", trajectory_file=\"gmx_infiles/ala_300K_TP_long.trr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the descriptors for one of them to infer the number of inputs for our model\n",
    "descriptors_for_tp = await wrapped_transform(tp_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await wrapped_alphaR(tp_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await wrapped_C7_eq(tp_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for model\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit 1 is 107 units wide.\n",
      "ResUnit 2 is 66 units wide.\n",
      "ResUnit 3 is 41 units wide.\n",
      "ResUnit 4 is 25 units wide.\n",
      "ResUnit 5 is 16 units wide.\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "n_lay_pyramid = 5\n",
    "#n_lay_pyramid = 4\n",
    "n_unit_top = 10\n",
    "#n_unit_top = 6\n",
    "n_unit_base = cv_ndim = descriptors_for_tp.shape[1]\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid))\n",
    "\n",
    "modules = []\n",
    "\n",
    "for i in range(1, n_lay_pyramid + 1):\n",
    "    print(f\"ResUnit {i} is {max(n_unit_top, int(n_unit_base * fact**(i-1)))} units wide.\")\n",
    "    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                              n_blocks=1)\n",
    "                ]\n",
    "\n",
    "    modules += [aimmd.pytorch.networks.FFNet(n_in=max(n_unit_top, int(n_unit_base * fact**(i-1))),\n",
    "                                             n_hidden=[max(n_unit_top, int(n_unit_base * fact**i))],  # 1 hidden layer network\n",
    "                                             activation=torch.nn.Identity(),\n",
    "                                             )\n",
    "                ]\n",
    "#    modules += [aimmd.pytorch.networks.ResNet(n_units=max(n_unit_top, int(n_unit_base * fact**i)),\n",
    "#                                              n_blocks=1)\n",
    "#                ]\n",
    "\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\n",
    "                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\n",
    "                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\n",
    "                                                 modules=modules,  # modules is a list of initialized torch.nn.Modules from arcd.pytorch.networks\n",
    "                                                 )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "\n",
    "# choose and initialize an optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# create a pyramidal feed-forward architecture with a ResNet top part\\nn_lay_pyramid = 4  # number of layers in the pyramid\\nn_unit_top = 10  # number of units per layer in the top ResNet part\\nn_lay_top = 2  # number of ResUnits in the top part, results in n_lay_top * residual_n_skip layers\\nn_unit_base = cv_ndim  # number of inputs to the NN/number of units in the first layer\\nprint('number of input descriptors: ', n_unit_base)\\n\\n# calculate the factor by which we reduce the number of units per layer in the pyramidal part from layer to layer\\nfact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid-1))\\n\\nffnet = aimmd.pytorch.networks.FFNet(n_in=cv_ndim,\\n                                     n_hidden=[max(n_unit_top, int(n_unit_base * fact**i)) for i in range(n_lay_pyramid)],  # 4 hidden layer pyramidal network\\n                                     #activation=nn.ELU,\\n                                    )\\n\\nresnet = aimmd.pytorch.networks.ResNet(n_units=n_unit_top, n_blocks=n_lay_top)\\n\\ntorch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\\n                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\\n                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\\n                                                 modules=[ffnet, resnet],  # modules is a list of initialized torch.nn.Modules from aimmd.pytorch.networks\\n                                                )\\n\\n# move model to GPU if CUDA is available\\nif torch.cuda.is_available():\\n    torch_model = torch_model.to('cuda')\\n\\n# choose and initialize an optimizer to train the model\\noptimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)\\n#\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# create a pyramidal feed-forward architecture with a ResNet top part\n",
    "n_lay_pyramid = 4  # number of layers in the pyramid\n",
    "n_unit_top = 10  # number of units per layer in the top ResNet part\n",
    "n_lay_top = 2  # number of ResUnits in the top part, results in n_lay_top * residual_n_skip layers\n",
    "n_unit_base = cv_ndim  # number of inputs to the NN/number of units in the first layer\n",
    "print('number of input descriptors: ', n_unit_base)\n",
    "\n",
    "# calculate the factor by which we reduce the number of units per layer in the pyramidal part from layer to layer\n",
    "fact = (n_unit_top / n_unit_base)**(1./(n_lay_pyramid-1))\n",
    "\n",
    "ffnet = aimmd.pytorch.networks.FFNet(n_in=cv_ndim,\n",
    "                                     n_hidden=[max(n_unit_top, int(n_unit_base * fact**i)) for i in range(n_lay_pyramid)],  # 4 hidden layer pyramidal network\n",
    "                                     #activation=nn.ELU,\n",
    "                                    )\n",
    "\n",
    "resnet = aimmd.pytorch.networks.ResNet(n_units=n_unit_top, n_blocks=n_lay_top)\n",
    "\n",
    "torch_model = aimmd.pytorch.networks.ModuleStack(n_out=1,  # using a single output we will predict only p_B and use a binomial loss\n",
    "                                                           # we could have also used n_out=n_states to use a multinomial loss and predict all states,\n",
    "                                                           # but this is probably only worthwhile if n_states > 2 as it would increase the number of free parameters in the NN\n",
    "                                                 modules=[ffnet, resnet],  # modules is a list of initialized torch.nn.Modules from aimmd.pytorch.networks\n",
    "                                                )\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    torch_model = torch_model.to('cuda')\n",
    "\n",
    "# choose and initialize an optimizer to train the model\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=1e-3)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take an ExpectedEfficiencyPytorchRCModel,\n",
    "# this RCmodel scales the learning rate by the expected efficiency factor (1 - n_TP_true / n_TP_expected)**2\n",
    "model = aimmd.pytorch.EEScalePytorchRCModelAsync(nnet=torch_model,\n",
    "                                                 optimizer=optimizer,\n",
    "                                                 states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "                                                 ee_params={'lr_0': 1e-3,  \n",
    "                                                            #'lr_min': 5e-5,  # lr_min = lr_0 / 20 is a good choice empirically\n",
    "                                                            'lr_min': 5e-5,\n",
    "                                                            #'epochs_per_train': 3, # try 5, [10 and 15] next\n",
    "                                                            'epochs_per_train': 5,\n",
    "                                                            #'interval': 5,\n",
    "                                                            'interval': 10,\n",
    "                                                            #'window': 75,\n",
    "                                                            'window': 100,\n",
    "                                                           },\n",
    "                                                 descriptor_transform=wrapped_transform,\n",
    "                                                 cache_file=storage,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(aimmd.pytorch.rcmodel.EEScalePytorchRCModel,\n",
       " aimmd.pytorch.rcmodel.EEScalePytorchRCModelMixin,\n",
       " aimmd.pytorch.rcmodel.PytorchRCModel,\n",
       " aimmd.base.rcmodel.RCModel,\n",
       " abc.ABC,\n",
       " object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aimmd.pytorch.EEScalePytorchRCModel.__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(aimmd.pytorch.rcmodel.EEScalePytorchRCModelAsync,\n",
       " aimmd.pytorch.rcmodel.EEScalePytorchRCModelMixin,\n",
       " aimmd.pytorch.rcmodel.PytorchRCModelAsync,\n",
       " aimmd.base.rcmodel.RCModelAsyncMixin,\n",
       " aimmd.pytorch.rcmodel.PytorchRCModel,\n",
       " aimmd.base.rcmodel.RCModel,\n",
       " abc.ABC,\n",
       " object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aimmd.pytorch.EEScalePytorchRCModelAsync.__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could use a list with initialized movers\n",
    "#movers = [[aimmdd.TwoWayShootingPathMover(states=[wrapped_C7_eq, wrapped_alphaR],\n",
    "#                                          engine_cls=gmx_engine_cls,\n",
    "#                                          engine_kwargs=gmx_engine_kwargs,\n",
    "#                                          engine_config=mdp,\n",
    "#                                          walltime_per_part=0.01,\n",
    "#                                          T=mdp[\"ref-t\"][0],\n",
    "#                                         )\n",
    "#           ] for i in range(n_chains)\n",
    "#         ]\n",
    "\n",
    "# it is easier though to use the `Brain.chains_from_moverlist()` function\n",
    "# this function will create n-chain identical PathSamplingChains where the movers for each chain are\n",
    "# specified by movers_cls (a list of mover classes) and movers_kwargs (a dict with keyword arguments used for initialization of the movers)\n",
    "movers_cls = [aimmdd.pathmovers.TwoWayShootingPathMover]\n",
    "movers_kwargs = [{'states': [wrapped_alphaR, wrapped_C7_eq],\n",
    "                  'engine_cls': gmx_engine_cls,\n",
    "                  'engine_kwargs': gmx_engine_kwargs,\n",
    "                  # NOTE: choose this as short as possible!\n",
    "                  #       since ala is super-small and commits fast we should make sure\n",
    "                  #       that most trials reach a state in the first part\n",
    "                  #       this in turn makes sure that we do not call gromasc multiple times per trial (saving setup time)\n",
    "                  #       but still ensures that the resulting trajectories are not too long and large\n",
    "                  #       it also reduces the time needed per step (we need at least walltime_per_part hours per step)\n",
    "                  #'walltime_per_part': 0.000015625,  # 0.055125 s per part\n",
    "                  #'walltime_per_part': 0.00003125,  # 0.1125 s per part\n",
    "                  'walltime_per_part': 0.0000625,  # 0.225 s per part\n",
    "                  #'walltime_per_part': 0.000125,  # 0.45 s per part\n",
    "                  #'walltime_per_part': 0.00025,  # 0.9 s per part\n",
    "                  #'walltime_per_part': 0.0005,  # 1.8 s per part\n",
    "                  #'walltime_per_part': 0.001,  # 3.6 s per part\n",
    "                  #'walltime_per_part': 0.002,  # 7.2 s per part\n",
    "                  #'walltime_per_part': 0.003,  # 10.8 s per part\n",
    "                  #'walltime_per_part': 0.004,  # 14.4 s per part\n",
    "                  'T': mdp[\"ref-t\"][0],\n",
    "                  \"sp_selector\": aimmdd.pathmovers.RCModelSPSelector(),  # can be used to customize SP-selection params \n",
    "                  }\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = aimmd.TrainSet(n_states=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [aimmdd.pathsampling.TrainingTask(model=model, trainset=trainset),\n",
    "         aimmdd.pathsampling.SaveTask(storage=storage, model=model, trainset=trainset),\n",
    "         aimmdd.pathsampling.DensityCollectionTask(model=model,\n",
    "                                                   first_collection=100,\n",
    "                                                   recreate_interval=500,\n",
    "                                                   interval=10\n",
    "                                                   ),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this would be the full __init__ call to the brain\n",
    "# it gives you full flexibility of setting up every PathSamplingChain individually\n",
    "#brain = aimmdd.Brain(model=model, workdir=workdir, storage=storage, movers=movers, mover_weights=[[1.], [1.], [1.]], tasks=tasks)\n",
    "\n",
    "# this is the 'easy' way\n",
    "brain = aimmdd.Brain.chains_from_moverlist(model=model, workdir=workdir, storage=storage, n_chain=n_chains,\n",
    "                                           movers_cls=movers_cls, movers_kwargs=movers_kwargs, tasks=tasks)\n",
    "                                           # Note that we left mover_weights=None at its default, this results\n",
    "                                           # in uniform weights for all movers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 0:  None\n",
      "\n",
      "Chain 1:  None\n",
      "\n",
      "Chain 2:  None\n",
      "\n",
      "Chain 3:  None\n",
      "\n",
      "Chain 0: \n",
      "MCstep <aimmd.distributed.pathmovers.MCstep object at 0x7f05fc52fac0>, with path Trajectory(trajectory_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr, structure_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Chain 1: \n",
      "MCstep <aimmd.distributed.pathmovers.MCstep object at 0x7f05fc52f550>, with path Trajectory(trajectory_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr, structure_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Chain 2: \n",
      "MCstep <aimmd.distributed.pathmovers.MCstep object at 0x7f05fc52fa60>, with path Trajectory(trajectory_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr, structure_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n",
      "Chain 3: \n",
      "MCstep <aimmd.distributed.pathmovers.MCstep object at 0x7f05fc52fa00>, with path Trajectory(trajectory_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/TP_low_barrier_300K_amber99sbildn.trr, structure_file=/home/think/Documents/sources/OPS/aimmd/examples/distributed/gmx_infiles/ala_300K_amber99sb-ildn.tpr).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: old cumbersome setup\n",
    "\n",
    "#initial_step = aimmdd.logic.MCstep(mover=None, stepnum=0, directory=\"gmx_infiles\", path=tp_short, accepted=True)\n",
    "#initial_step2 = aimmdd.logic.MCstep(mover=None, stepnum=0, directory=\"gmx_infiles\", path=tp_long, accepted=True)\n",
    "\n",
    "# take two different initial TPs\n",
    "#for i, c in enumerate(brain.chains):\n",
    "#    if i == 2:\n",
    "#        c.current_step = initial_step2\n",
    "#        c.chainstore.append(initial_step2)  # save the initial step as first step of every chain\n",
    "#    else:\n",
    "#        c.current_step = initial_step\n",
    "#        c.chainstore.append(initial_step)  # save the initial step as first step of every chain\n",
    "\n",
    "\n",
    "# NEW: use the new seed_initial_paths() method!\n",
    "# have a look at before\n",
    "for i, c in enumerate(brain.chains):\n",
    "    print(f\"Chain {i}: \", c.current_step)\n",
    "    print()\n",
    "# seed them\n",
    "#brain.seed_initial_paths(trajectories=[tp_short, tp2_short, tp_long], weights=[1., 1., 2.])\n",
    "brain.seed_initial_paths(trajectories=[tp_lb], weights=[1.])\n",
    "# have a look again\n",
    "for i, c in enumerate(brain.chains):\n",
    "    print(f\"Chain {i}: \")\n",
    "    print(f\"MCstep {c.current_step}, with path {c.current_step.path}.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await brain.run_for_n_steps(500)\n",
    "#await brain.run_for_n_steps(2000)\n",
    "#await brain.run_for_n_accepts(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.log_train_decision[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at the value of the learning rate over the course of training\n",
    "# note however, that we did not train at every step, but just at every interval MCsteps\n",
    "log_train = np.array(model.log_train_decision)\n",
    "lr = log_train[:,1]\n",
    "plt.plot(lr, label='lr')\n",
    "# see where we really trained: everywhere where train=True\n",
    "# set lr_true to NaN anywhere where we did not train to have a nice plot\n",
    "lr_true = lr\n",
    "lr_true[log_train[:,0] == False] = np.nan\n",
    "plt.plot(lr_true, '+', label='True learning')\n",
    "# lr_min as a guide to the eye\n",
    "plt.axhline(model.ee_params['lr_min'], label='lr_min', color='lime')\n",
    "plt.legend()\n",
    "plt.xlabel('MCStep', size=15);\n",
    "plt.ylabel('Learning rate', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model losses at each step where it trained\n",
    "# this will be epochs_per_training loss values per training\n",
    "plt.plot(model.log_train_loss, label='training loss')\n",
    "plt.legend();\n",
    "plt.ylabel('loss per training point', size=15)\n",
    "plt.xlabel('training step', size=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resort such that we have a loss value per MCStep, NaN if we did not train at that step\n",
    "train_loss = []\n",
    "count = 0\n",
    "for t in log_train[:, 0]:\n",
    "    if t:\n",
    "        train_loss.append(model.log_train_loss[count])\n",
    "        count += 1\n",
    "    else:\n",
    "        train_loss.append([np.nan for _ in range(model.ee_params['epochs_per_train'])])\n",
    "    \n",
    "plt.plot(train_loss, '+', label='training loss')\n",
    "plt.legend();\n",
    "plt.ylabel('loss per training point', size=15)\n",
    "plt.xlabel('MCStep', size=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a way, currently it is not possibly to get the accepts in the same order as the trainset?!\n",
    "# TODO: probably we will have to write a DataCollectionTask to achieve that ?!\n",
    "# get accepts from storage:\n",
    "# NOTE: this is just roughly the right order\n",
    "accepts = []\n",
    "for accs in zip(*(c.accepts for c in brain.chains)):\n",
    "    accepts += list(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot efficiency, expected efficiency and accepts\n",
    "# Note: this will only work for models with n_out=1, due to the way we calculate p(TP|x)\n",
    "\n",
    "p_ex = np.array(model.expected_p)\n",
    "\n",
    "l, = plt.plot(np.cumsum(trainset.transitions), label='generated');\n",
    "plt.plot(np.cumsum(accepts), c=l.get_color(), ls='--', label='accepted');\n",
    "plt.plot(np.cumsum(2*p_ex*(1 - p_ex)),c=l.get_color(), ls=':', label='expected');\n",
    "plt.plot(np.cumsum(2*p_ex*(1 - p_ex))- np.cumsum(trainset.transitions), label='diff (expected - generated)')\n",
    "plt.plot(np.linspace(0., len(trainset)/2., len(trainset)), c='k', ls='--', label='maximal', lw=2)\n",
    "plt.legend(fontsize=12);\n",
    "plt.ylabel('Cummulative count of TPs', size=15)\n",
    "plt.xlabel('cummulative MC Steps', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipr = aimmd.analysis.HIPRanalysis(model, trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipr_plus_losses, hipr_plus_stds = hipr.do_hipr_plus(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_diffs = hipr_plus_losses[:-1] - hipr_plus_losses[-1]  # hipr_losses[-1] is the reference loss over the unaltered trainset\n",
    "\n",
    "plt.bar(np.arange(len(loss_diffs)), loss_diffs, yerr=hipr_plus_stds[:-1])\n",
    "plt.xlabel('Coordinate index', size=15)\n",
    "plt.ylabel('Relative importance', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_funcs_mda import generate_atomgroups_for_ic\n",
    "\n",
    "u = mda.Universe(\"gmx_infiles/ala_300K_amber99sb-ildn.tpr\", \"gmx_infiles/conf.gro\",\n",
    "                 refresh_offsets=True, tpr_resid_from_one=True)\n",
    "molecule = u.select_atoms('protein')\n",
    "pairs, triples, quadruples = generate_atomgroups_for_ic(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the most important contributors?\n",
    "max_idxs = np.argsort(loss_diffs)[::-1]\n",
    "sf_parms = {}\n",
    "\n",
    "#pairs, triples, quadruples = aimmd.coords.internal.generate_indices(traj.topology, source_idx=1)\n",
    "\n",
    "ic_parms = {\"pairs\": pairs, \"triples\": triples, \"quadruples\": quadruples}\n",
    "\n",
    "print('reference loss:', hipr_plus_losses[-1])\n",
    "for idx in max_idxs[:10]:\n",
    "    print()\n",
    "    print('loss for idx {:d}: '.format(idx), hipr_plus_losses[idx])\n",
    "    if idx < len(pairs[0]):\n",
    "        print(f\"bond between: {pairs[0][idx]} and {pairs[1][idx]}\")\n",
    "        continue\n",
    "    idx -= len(pairs[0])\n",
    "    if idx < len(triples[0]):\n",
    "        print(f\"angle between {triples[0][idx]}, {triples[1][idx]} and {triples[2][idx]}\")\n",
    "        continue\n",
    "    idx -= len(triples[0])\n",
    "    if idx % 2 == 0:\n",
    "        st = \"sinus\"\n",
    "    else:\n",
    "        st = \"cosinus\"\n",
    "    st += f\" of dihedral between {quadruples[0][idx // 2]}, {quadruples[1][idx // 2]}, {quadruples[2][idx // 2]} and {quadruples[3][idx // 2]}.\"\n",
    "    print(st)\n",
    "    #print(aimmd.coords.get_involved(idx, sf_parms=sf_parms, ic_parms=ic_parms, solvent_atoms=[['O', 'H']], solvent_resname=['HOH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the last model\n",
    "storage.rcmodels[\"model_to_continue_with\"] = model\n",
    "storage.save_trainset(trainset)\n",
    "# the rest should be saved automatically\n",
    "# maybe we should save the model + trainset at the end of the simulation autmatically too?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/gromacs-2020.4/bin/gmx\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "which gmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 107)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(await wrapped_transform(storage.central_memory[0][8].path)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n",
      "False\n",
      "<aimmd.distributed.pathmovers.TwoWayShootingPathMover object at 0x7f028248fb50>\n",
      "False\n",
      "False\n",
      "<aimmd.distributed.pathmovers.TwoWayShootingPathMover object at 0x7f0282dc9ac0>\n",
      "False\n",
      "False\n",
      "<aimmd.distributed.pathmovers.TwoWayShootingPathMover object at 0x7f02824739a0>\n",
      "False\n",
      "False\n",
      "<aimmd.distributed.pathmovers.TwoWayShootingPathMover object at 0x7f0282379a60>\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for s in brain.storage.central_memory[0][:5]:\n",
    "    print(s.mover)\n",
    "    print(s.mover is brain.chains[0].movers[0])\n",
    "    print(s.mover == brain.chains[0].movers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMMD nature publish (py3.7.3/June-2021)",
   "language": "python",
   "name": "aimmd_nature_publish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
